{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep - Raw Data\n",
    "This notebook documents my work on the [UK High-value Customers dataset](https://www.kaggle.com/vik2012kvs/high-value-customers-identification) from a Data Engineering and Feature Engineering perspective.\n",
    "\n",
    "An essential part of any Data Science project is understanding the data that we are working with. I will use this workspace to identify the major characteristics of the dataset, identify its granularity and address issues with it. I will also process the data in a way that can be used in further analysis. \n",
    "\n",
    "The plan for this part of the project is the following:\n",
    "\n",
    "1. Process the raw dataset so that it can be realibly used for modelling and analysis;\n",
    "2. Split the raw dataset into different views that are relevant to the context of Customer Segmentation and Ecommerce companies;\n",
    "3. Prepare the dataset for downstream tasks;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install inflection nb_black >> ../configs/dependencies/package_installation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# loading magic commands:\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_formatted_code = \"# loading magic commands:\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading magic commands:\n",
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"###### Loading the necessary libraries #########\\n\\n# PySpark dependencies:\\nimport pyspark\\nfrom pyspark import SparkConf\\nfrom pyspark import SparkContext\\nfrom pyspark.sql import SparkSession\\nfrom pyspark.sql import SQLContext\\nimport pyspark.sql.functions as F\\nfrom pyspark.sql.functions import udf\\nimport pyspark.sql.types as Ts\\nfrom pyspark.sql.window import Window\\n\\n# database utilities:\\nimport pandas as pd\\n\\n# other relevant libraries:\\nimport warnings\\nimport inflection\\nimport unicodedata\\nfrom datetime import datetime, timedelta\\nimport json \\nimport re\\nimport os\\nfrom glob import glob\\nimport shutil\\nimport itertools\\n\\n# setting global parameters for visualizations:\\nwarnings.filterwarnings('ignore')\\npd.set_option(\\\"display.precision\\\", 4)\\npd.set_option(\\\"display.float_format\\\", lambda x: '%.2f' % x)\";\n",
       "                var nbb_formatted_code = \"###### Loading the necessary libraries #########\\n\\n# PySpark dependencies:\\nimport pyspark\\nfrom pyspark import SparkConf\\nfrom pyspark import SparkContext\\nfrom pyspark.sql import SparkSession\\nfrom pyspark.sql import SQLContext\\nimport pyspark.sql.functions as F\\nfrom pyspark.sql.functions import udf\\nimport pyspark.sql.types as Ts\\nfrom pyspark.sql.window import Window\\n\\n# database utilities:\\nimport pandas as pd\\n\\n# other relevant libraries:\\nimport warnings\\nimport inflection\\nimport unicodedata\\nfrom datetime import datetime, timedelta\\nimport json\\nimport re\\nimport os\\nfrom glob import glob\\nimport shutil\\nimport itertools\\n\\n# setting global parameters for visualizations:\\nwarnings.filterwarnings(\\\"ignore\\\")\\npd.set_option(\\\"display.precision\\\", 4)\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.2f\\\" % x)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Loading the necessary libraries #########\n",
    "\n",
    "# PySpark dependencies:\n",
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.types as Ts\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# database utilities:\n",
    "import pandas as pd\n",
    "\n",
    "# other relevant libraries:\n",
    "import warnings\n",
    "import inflection\n",
    "import unicodedata\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "# setting global parameters for visualizations:\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Configuring Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# loading the configurations needed for Spark\\ndef init_spark(app_name):\\n\\n    spark = (\\n        SparkSession.builder.appName(app_name)\\n        .config(\\\"spark.files.overwrite\\\", \\\"true\\\")\\n        .config(\\\"spark.sql.repl.eagerEval.enabled\\\", True)\\n        .config(\\\"spark.sql.repl.eagerEval.maxNumRows\\\", 5)\\n        .config(\\\"spark.sql.legacy.timeParserPolicy\\\", \\\"LEGACY\\\")\\n        .config(\\\"spark.sql.parquet.compression.codec\\\", \\\"gzip\\\")\\n        .enableHiveSupport()\\n        .getOrCreate()\\n    )\\n\\n    return spark\\n\\n\\n# init the spark session:\\nspark = init_spark(\\\"Raw Data Preparation\\\")\";\n",
       "                var nbb_formatted_code = \"# loading the configurations needed for Spark\\ndef init_spark(app_name):\\n\\n    spark = (\\n        SparkSession.builder.appName(app_name)\\n        .config(\\\"spark.files.overwrite\\\", \\\"true\\\")\\n        .config(\\\"spark.sql.repl.eagerEval.enabled\\\", True)\\n        .config(\\\"spark.sql.repl.eagerEval.maxNumRows\\\", 5)\\n        .config(\\\"spark.sql.legacy.timeParserPolicy\\\", \\\"LEGACY\\\")\\n        .config(\\\"spark.sql.parquet.compression.codec\\\", \\\"gzip\\\")\\n        .enableHiveSupport()\\n        .getOrCreate()\\n    )\\n\\n    return spark\\n\\n\\n# init the spark session:\\nspark = init_spark(\\\"Raw Data Preparation\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading the configurations needed for Spark\n",
    "def init_spark(app_name):\n",
    "\n",
    "    spark = (\n",
    "        SparkSession.builder.appName(app_name)\n",
    "        .config(\"spark.files.overwrite\", \"true\")\n",
    "        .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "        .config(\"spark.sql.repl.eagerEval.maxNumRows\", 5)\n",
    "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "        .config(\"spark.sql.parquet.compression.codec\", \"gzip\")\n",
    "        .enableHiveSupport()\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "    return spark\n",
    "\n",
    "\n",
    "# init the spark session:\n",
    "spark = init_spark(\"Raw Data Preparation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://84a2e6cc83b5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Raw Data Preparation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff0dffa3760>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# verifying the spark session:\\nspark\";\n",
       "                var nbb_formatted_code = \"# verifying the spark session:\\nspark\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verifying the spark session:\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"def save_to_filesystem(df, target_path, parquet_path, filename):\\n    \\\"\\\"\\\"Helper function to save pyspark dataframes as parquets in a way that is similar to writing to local files\\n\\n    Args:\\n        df (pyspark.sql.dataframe.DataFrame): dataframe to be saved\\n        target_path (str): path that will store the file\\n        filename (str): name of the resulting file\\n\\n    Returns:\\n        None\\n    \\\"\\\"\\\"\\n    PARQUET_FILE = f\\\"{target_path}/{parquet_path}\\\"\\n    OUTPUT_FILE = f\\\"{target_path}/{filename}\\\"\\n\\n    if os.path.exists(PARQUET_FILE):\\n        shutil.rmtree(\\n            PARQUET_FILE\\n        )  # if the directory already exists, remove it (throws error if not)\\n\\n    # saves the dataframe:\\n    df.coalesce(1).write.save(PARQUET_FILE)\\n\\n    # retrieves file resulting from the saving procedure:\\n    original_file = glob(f\\\"{PARQUET_FILE}/*.parquet\\\")[0]\\n\\n    # renames the resulting file and saves it to the target directory:\\n    os.rename(original_file, OUTPUT_FILE)\\n\\n    shutil.rmtree(PARQUET_FILE)\\n\\n    return True\\n\\n\\ndef apply_category_map(category_map):\\n    \\\"\\\"\\\"Helper function to convert strings given a map\\n\\n    Note:\\n        This function uses the function generator scheme, much like the PySpark code\\n\\n    Args:\\n        original_category (str): the original category name\\n        category_map (dict): the hash table or dictionary for converting the values:\\n\\n    Returns:\\n        new_category (str): the resulting category\\n\\n    \\\"\\\"\\\"\\n\\n    def func(row):\\n        try:\\n            result = category_map[row]\\n        except:\\n            result = None\\n        return result\\n\\n    return F.udf(func)\\n\\n\\ndef get_datetime_features(df, time_col):\\n    \\\"\\\"\\\"Function to extract time-based features from pyspark dataframes\\n\\n    Args:\\n        df (pyspark.sql.dataframe.DataFrame): the original dataframe that needs to be enriched\\n        time_col (str): the string name of the column containing the date object\\n\\n    Returns:\\n        df (pyspark.sql.dataframe.DataFrame): resulting pyspark dataframe with the added features\\n            -> See list of attribute the source code for the attributes\\n\\n    \\\"\\\"\\\"\\n\\n    # applying date-related functions:\\n\\n    # day-level attributes:\\n    df = df.withColumn(\\\"day_of_week\\\", F.dayofweek(F.col(time_col)))\\n\\n    df = df.withColumn(\\\"day_of_month\\\", F.dayofmonth(F.col(time_col)))\\n\\n    df = df.withColumn(\\\"day_of_year\\\", F.dayofyear(F.col(time_col)))\\n\\n    # week-level attributes:\\n    df = df.withColumn(\\\"week_of_year\\\", F.weekofyear(F.col(time_col)))\\n\\n    # month-level attributes:\\n    df = df.withColumn(\\\"month\\\", F.month(F.col(time_col)))\\n\\n    df = df.withColumn(\\\"quarter\\\", F.quarter(F.col(time_col)))\\n\\n    # year-level attributes:\\n    df = df.withColumn(\\\"year\\\", F.year(F.col(time_col)))\\n\\n    return df\\n\\n\\ndef bulk_aggregate(df, group_col, aggs, target_cols):\\n    \\\"\\\"\\\"Wrapper function to apply multiple aggregations when performing group bys\\n\\n    It utilizes the spark's SQL Context and string interpolation to perform the aggregation using SQL syntax.\\n\\n    Args:\\n        df (pyspark.sql.dataframe.DataFrame): dataframe with raw data\\n        group_col (str): the column that will be used for grouping\\n        aggs (list): list of aggregations that want to be made (must be the same name as pyspark.sql.functions)\\n        target_cols (str): columns in which aggregations will be performed\\n\\n    Returns:\\n        df_grouped (pyspark.sql.dataframe.DataFrame): dataframe with the grouped data\\n    \\\"\\\"\\\"\\n\\n    # buils the cartersian product of the lists\\n    aggs_to_perform = itertools.product(aggs, target_cols)\\n\\n    Q_LAYOUT = \\\"\\\"\\\"\\n    SELECT\\n        {},\\n        {}\\n        FROM df\\n        GROUP BY {}\\n    \\\"\\\"\\\"\\n\\n    aggregations = []\\n    for agg, col in aggs_to_perform:\\n\\n        # builds the string for aggregation\\n        statement = f\\\"{agg.upper()}({col}) as {agg}_{col}\\\"\\n        aggregations.append(statement)\\n\\n    full_statement = \\\",\\\\n\\\".join(aggregations)\\n\\n    # uses string interpolation to build the full query statement\\n    QUERY = Q_LAYOUT.format(group_col, full_statement, group_col)\\n\\n    # registers the dataframe as temporary table:\\n    df.registerTempTable(\\\"df\\\")\\n    df_grouped = spark.sql(QUERY)\\n\\n    # rounds values:\\n    for column in df_grouped.columns:\\n        df_grouped = df_grouped.withColumn(column, F.round(F.col(column), 1))\\n\\n    return df_grouped\\n\\n\\n######### Text Processing Functions ########\\n@udf(\\\"string\\\")\\ndef normalize_text(text):\\n    \\\"\\\"\\\"Helper function to normalize text data to ASCII and lower case, removing spaces\\n\\n    Args:\\n        text (string): the string that needs to be normalized\\n\\n    Returns:\\n        text (string): cleaned up string\\n\\n    \\\"\\\"\\\"\\n    regex = r\\\"[^a-zA-Z0-9]+\\\"\\n\\n    if text is not None:\\n\\n        text = str(text)\\n        text = text.lower()\\n        text = re.sub(regex, \\\" \\\", text)\\n        text = text.strip()\\n        text = str(\\n            unicodedata.normalize(\\\"NFKD\\\", text).encode(\\\"ASCII\\\", \\\"ignore\\\"), \\\"utf-8\\\"\\n        )\\n\\n    return text\\n\\n\\ndef get_null_columns(df, normalize=False):\\n    \\\"\\\"\\\"Helper function to print the number of null records for each column of a PySpark DataFrame.\\n\\n    Args:\\n        df (pyspark.sql.dataframe.DataFrame): a PySpark Dataframe object\\n\\n    Returns:\\n        None -> prints to standard out\\n\\n    \\\"\\\"\\\"\\n\\n    if normalize:\\n        total = df.count()\\n\\n        df_nulls = df.select(\\n            [\\n                (F.sum(F.when(F.col(column).isNull(), 1).otherwise(0)) / total).alias(\\n                    column\\n                )\\n                for column in df.columns\\n            ]\\n        )\\n\\n    else:\\n        df_nulls = df.select(\\n            [\\n                F.sum(F.when(F.col(column).isNull(), 1).otherwise(0)).alias(column)\\n                for column in df.columns\\n            ]\\n        )\\n\\n    # displaying the results to standard out\\n    df_nulls.show(1, truncate=False, vertical=True)\\n\\n\\n@udf(\\\"boolean\\\")\\ndef is_set_or_pack(text):\\n\\n    # description entries to match:\\n    set_descriptions = {\\\"set\\\", \\\"set of\\\", \\\"pack\\\", \\\"pack of\\\", \\\"box\\\", \\\"box of\\\"}\\n\\n    if text is not None:\\n        text = str(text)\\n\\n        if text in set_descriptions:\\n            return True\\n\\n        else:\\n            return False\\n\\n    else:\\n        return False\\n\\n\\n@udf(\\\"integer\\\")\\ndef get_unit_size(text):\\n\\n    if text is not None:\\n        check_if_digit = len(re.findall(r\\\"(\\\\d+)\\\", text)) > 0\\n\\n        if check_if_digit:\\n            set_size = int(re.findall(r\\\"(\\\\d+)\\\", text)[0])\\n            return set_size\\n\\n        else:\\n            return 1\\n\\n    else:\\n        return 1\\n\\n\\n@udf(\\\"boolean\\\")\\ndef has_non_digits_only(text):\\n    \\\"\\\"\\\"Function to match entries in the dataset that are purely non-digit characters\\n\\n    Args:\\n        text (str): string containing the invoice code\\n\\n    Returns:\\n        boolean: whether the text contains non-digit characters and is not related to cancellations\\n\\n    \\\"\\\"\\\"\\n\\n    if text is not None:\\n        condition = all(character.isalpha() for character in text)\\n\\n        if condition:\\n            return True\\n\\n        else:\\n            return False\\n\\n    else:\\n        return False\";\n",
       "                var nbb_formatted_code = \"def save_to_filesystem(df, target_path, parquet_path, filename):\\n    \\\"\\\"\\\"Helper function to save pyspark dataframes as parquets in a way that is similar to writing to local files\\n\\n    Args:\\n        df (pyspark.sql.dataframe.DataFrame): dataframe to be saved\\n        target_path (str): path that will store the file\\n        filename (str): name of the resulting file\\n\\n    Returns:\\n        None\\n    \\\"\\\"\\\"\\n    PARQUET_FILE = f\\\"{target_path}/{parquet_path}\\\"\\n    OUTPUT_FILE = f\\\"{target_path}/{filename}\\\"\\n\\n    if os.path.exists(PARQUET_FILE):\\n        shutil.rmtree(\\n            PARQUET_FILE\\n        )  # if the directory already exists, remove it (throws error if not)\\n\\n    # saves the dataframe:\\n    df.coalesce(1).write.save(PARQUET_FILE)\\n\\n    # retrieves file resulting from the saving procedure:\\n    original_file = glob(f\\\"{PARQUET_FILE}/*.parquet\\\")[0]\\n\\n    # renames the resulting file and saves it to the target directory:\\n    os.rename(original_file, OUTPUT_FILE)\\n\\n    shutil.rmtree(PARQUET_FILE)\\n\\n    return True\\n\\n\\ndef apply_category_map(category_map):\\n    \\\"\\\"\\\"Helper function to convert strings given a map\\n\\n    Note:\\n        This function uses the function generator scheme, much like the PySpark code\\n\\n    Args:\\n        original_category (str): the original category name\\n        category_map (dict): the hash table or dictionary for converting the values:\\n\\n    Returns:\\n        new_category (str): the resulting category\\n\\n    \\\"\\\"\\\"\\n\\n    def func(row):\\n        try:\\n            result = category_map[row]\\n        except:\\n            result = None\\n        return result\\n\\n    return F.udf(func)\\n\\n\\ndef get_datetime_features(df, time_col):\\n    \\\"\\\"\\\"Function to extract time-based features from pyspark dataframes\\n\\n    Args:\\n        df (pyspark.sql.dataframe.DataFrame): the original dataframe that needs to be enriched\\n        time_col (str): the string name of the column containing the date object\\n\\n    Returns:\\n        df (pyspark.sql.dataframe.DataFrame): resulting pyspark dataframe with the added features\\n            -> See list of attribute the source code for the attributes\\n\\n    \\\"\\\"\\\"\\n\\n    # applying date-related functions:\\n\\n    # day-level attributes:\\n    df = df.withColumn(\\\"day_of_week\\\", F.dayofweek(F.col(time_col)))\\n\\n    df = df.withColumn(\\\"day_of_month\\\", F.dayofmonth(F.col(time_col)))\\n\\n    df = df.withColumn(\\\"day_of_year\\\", F.dayofyear(F.col(time_col)))\\n\\n    # week-level attributes:\\n    df = df.withColumn(\\\"week_of_year\\\", F.weekofyear(F.col(time_col)))\\n\\n    # month-level attributes:\\n    df = df.withColumn(\\\"month\\\", F.month(F.col(time_col)))\\n\\n    df = df.withColumn(\\\"quarter\\\", F.quarter(F.col(time_col)))\\n\\n    # year-level attributes:\\n    df = df.withColumn(\\\"year\\\", F.year(F.col(time_col)))\\n\\n    return df\\n\\n\\ndef bulk_aggregate(df, group_col, aggs, target_cols):\\n    \\\"\\\"\\\"Wrapper function to apply multiple aggregations when performing group bys\\n\\n    It utilizes the spark's SQL Context and string interpolation to perform the aggregation using SQL syntax.\\n\\n    Args:\\n        df (pyspark.sql.dataframe.DataFrame): dataframe with raw data\\n        group_col (str): the column that will be used for grouping\\n        aggs (list): list of aggregations that want to be made (must be the same name as pyspark.sql.functions)\\n        target_cols (str): columns in which aggregations will be performed\\n\\n    Returns:\\n        df_grouped (pyspark.sql.dataframe.DataFrame): dataframe with the grouped data\\n    \\\"\\\"\\\"\\n\\n    # buils the cartersian product of the lists\\n    aggs_to_perform = itertools.product(aggs, target_cols)\\n\\n    Q_LAYOUT = \\\"\\\"\\\"\\n    SELECT\\n        {},\\n        {}\\n        FROM df\\n        GROUP BY {}\\n    \\\"\\\"\\\"\\n\\n    aggregations = []\\n    for agg, col in aggs_to_perform:\\n\\n        # builds the string for aggregation\\n        statement = f\\\"{agg.upper()}({col}) as {agg}_{col}\\\"\\n        aggregations.append(statement)\\n\\n    full_statement = \\\",\\\\n\\\".join(aggregations)\\n\\n    # uses string interpolation to build the full query statement\\n    QUERY = Q_LAYOUT.format(group_col, full_statement, group_col)\\n\\n    # registers the dataframe as temporary table:\\n    df.registerTempTable(\\\"df\\\")\\n    df_grouped = spark.sql(QUERY)\\n\\n    # rounds values:\\n    for column in df_grouped.columns:\\n        df_grouped = df_grouped.withColumn(column, F.round(F.col(column), 1))\\n\\n    return df_grouped\\n\\n\\n######### Text Processing Functions ########\\n@udf(\\\"string\\\")\\ndef normalize_text(text):\\n    \\\"\\\"\\\"Helper function to normalize text data to ASCII and lower case, removing spaces\\n\\n    Args:\\n        text (string): the string that needs to be normalized\\n\\n    Returns:\\n        text (string): cleaned up string\\n\\n    \\\"\\\"\\\"\\n    regex = r\\\"[^a-zA-Z0-9]+\\\"\\n\\n    if text is not None:\\n\\n        text = str(text)\\n        text = text.lower()\\n        text = re.sub(regex, \\\" \\\", text)\\n        text = text.strip()\\n        text = str(\\n            unicodedata.normalize(\\\"NFKD\\\", text).encode(\\\"ASCII\\\", \\\"ignore\\\"), \\\"utf-8\\\"\\n        )\\n\\n    return text\\n\\n\\ndef get_null_columns(df, normalize=False):\\n    \\\"\\\"\\\"Helper function to print the number of null records for each column of a PySpark DataFrame.\\n\\n    Args:\\n        df (pyspark.sql.dataframe.DataFrame): a PySpark Dataframe object\\n\\n    Returns:\\n        None -> prints to standard out\\n\\n    \\\"\\\"\\\"\\n\\n    if normalize:\\n        total = df.count()\\n\\n        df_nulls = df.select(\\n            [\\n                (F.sum(F.when(F.col(column).isNull(), 1).otherwise(0)) / total).alias(\\n                    column\\n                )\\n                for column in df.columns\\n            ]\\n        )\\n\\n    else:\\n        df_nulls = df.select(\\n            [\\n                F.sum(F.when(F.col(column).isNull(), 1).otherwise(0)).alias(column)\\n                for column in df.columns\\n            ]\\n        )\\n\\n    # displaying the results to standard out\\n    df_nulls.show(1, truncate=False, vertical=True)\\n\\n\\n@udf(\\\"boolean\\\")\\ndef is_set_or_pack(text):\\n\\n    # description entries to match:\\n    set_descriptions = {\\\"set\\\", \\\"set of\\\", \\\"pack\\\", \\\"pack of\\\", \\\"box\\\", \\\"box of\\\"}\\n\\n    if text is not None:\\n        text = str(text)\\n\\n        if text in set_descriptions:\\n            return True\\n\\n        else:\\n            return False\\n\\n    else:\\n        return False\\n\\n\\n@udf(\\\"integer\\\")\\ndef get_unit_size(text):\\n\\n    if text is not None:\\n        check_if_digit = len(re.findall(r\\\"(\\\\d+)\\\", text)) > 0\\n\\n        if check_if_digit:\\n            set_size = int(re.findall(r\\\"(\\\\d+)\\\", text)[0])\\n            return set_size\\n\\n        else:\\n            return 1\\n\\n    else:\\n        return 1\\n\\n\\n@udf(\\\"boolean\\\")\\ndef has_non_digits_only(text):\\n    \\\"\\\"\\\"Function to match entries in the dataset that are purely non-digit characters\\n\\n    Args:\\n        text (str): string containing the invoice code\\n\\n    Returns:\\n        boolean: whether the text contains non-digit characters and is not related to cancellations\\n\\n    \\\"\\\"\\\"\\n\\n    if text is not None:\\n        condition = all(character.isalpha() for character in text)\\n\\n        if condition:\\n            return True\\n\\n        else:\\n            return False\\n\\n    else:\\n        return False\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_to_filesystem(df, target_path, parquet_path, filename):\n",
    "    \"\"\"Helper function to save pyspark dataframes as parquets in a way that is similar to writing to local files\n",
    "\n",
    "    Args:\n",
    "        df (pyspark.sql.dataframe.DataFrame): dataframe to be saved\n",
    "        target_path (str): path that will store the file\n",
    "        filename (str): name of the resulting file\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    PARQUET_FILE = f\"{target_path}/{parquet_path}\"\n",
    "    OUTPUT_FILE = f\"{target_path}/{filename}\"\n",
    "\n",
    "    if os.path.exists(PARQUET_FILE):\n",
    "        shutil.rmtree(\n",
    "            PARQUET_FILE\n",
    "        )  # if the directory already exists, remove it (throws error if not)\n",
    "\n",
    "    # saves the dataframe:\n",
    "    df.coalesce(1).write.save(PARQUET_FILE)\n",
    "\n",
    "    # retrieves file resulting from the saving procedure:\n",
    "    original_file = glob(f\"{PARQUET_FILE}/*.parquet\")[0]\n",
    "\n",
    "    # renames the resulting file and saves it to the target directory:\n",
    "    os.rename(original_file, OUTPUT_FILE)\n",
    "\n",
    "    shutil.rmtree(PARQUET_FILE)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def apply_category_map(category_map):\n",
    "    \"\"\"Helper function to convert strings given a map\n",
    "\n",
    "    Note:\n",
    "        This function uses the function generator scheme, much like the PySpark code\n",
    "\n",
    "    Args:\n",
    "        original_category (str): the original category name\n",
    "        category_map (dict): the hash table or dictionary for converting the values:\n",
    "\n",
    "    Returns:\n",
    "        new_category (str): the resulting category\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def func(row):\n",
    "        try:\n",
    "            result = category_map[row]\n",
    "        except:\n",
    "            result = None\n",
    "        return result\n",
    "\n",
    "    return F.udf(func)\n",
    "\n",
    "\n",
    "def get_datetime_features(df, time_col):\n",
    "    \"\"\"Function to extract time-based features from pyspark dataframes\n",
    "\n",
    "    Args:\n",
    "        df (pyspark.sql.dataframe.DataFrame): the original dataframe that needs to be enriched\n",
    "        time_col (str): the string name of the column containing the date object\n",
    "\n",
    "    Returns:\n",
    "        df (pyspark.sql.dataframe.DataFrame): resulting pyspark dataframe with the added features\n",
    "            -> See list of attribute the source code for the attributes\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # applying date-related functions:\n",
    "\n",
    "    # day-level attributes:\n",
    "    df = df.withColumn(\"day_of_week\", F.dayofweek(F.col(time_col)))\n",
    "\n",
    "    df = df.withColumn(\"day_of_month\", F.dayofmonth(F.col(time_col)))\n",
    "\n",
    "    df = df.withColumn(\"day_of_year\", F.dayofyear(F.col(time_col)))\n",
    "\n",
    "    # week-level attributes:\n",
    "    df = df.withColumn(\"week_of_year\", F.weekofyear(F.col(time_col)))\n",
    "\n",
    "    # month-level attributes:\n",
    "    df = df.withColumn(\"month\", F.month(F.col(time_col)))\n",
    "\n",
    "    df = df.withColumn(\"quarter\", F.quarter(F.col(time_col)))\n",
    "\n",
    "    # year-level attributes:\n",
    "    df = df.withColumn(\"year\", F.year(F.col(time_col)))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_aggregate(df, group_col, aggs, target_cols):\n",
    "    \"\"\"Wrapper function to apply multiple aggregations when performing group bys\n",
    "\n",
    "    It utilizes the spark's SQL Context and string interpolation to perform the aggregation using SQL syntax.\n",
    "\n",
    "    Args:\n",
    "        df (pyspark.sql.dataframe.DataFrame): dataframe with raw data\n",
    "        group_col (str): the column that will be used for grouping\n",
    "        aggs (list): list of aggregations that want to be made (must be the same name as pyspark.sql.functions)\n",
    "        target_cols (str): columns in which aggregations will be performed\n",
    "\n",
    "    Returns:\n",
    "        df_grouped (pyspark.sql.dataframe.DataFrame): dataframe with the grouped data\n",
    "    \"\"\"\n",
    "\n",
    "    # buils the cartersian product of the lists\n",
    "    aggs_to_perform = itertools.product(aggs, target_cols)\n",
    "\n",
    "    Q_LAYOUT = \"\"\"\n",
    "    SELECT\n",
    "        {},\n",
    "        {}\n",
    "        FROM df\n",
    "        GROUP BY {}\n",
    "    \"\"\"\n",
    "\n",
    "    aggregations = []\n",
    "    for agg, col in aggs_to_perform:\n",
    "\n",
    "        # builds the string for aggregation\n",
    "        statement = f\"{agg.upper()}({col}) as {agg}_{col}\"\n",
    "        aggregations.append(statement)\n",
    "\n",
    "    full_statement = \",\\n\".join(aggregations)\n",
    "\n",
    "    # uses string interpolation to build the full query statement\n",
    "    QUERY = Q_LAYOUT.format(group_col, full_statement, group_col)\n",
    "\n",
    "    # registers the dataframe as temporary table:\n",
    "    df.registerTempTable(\"df\")\n",
    "    df_grouped = spark.sql(QUERY)\n",
    "\n",
    "    # rounds values:\n",
    "    for column in df_grouped.columns:\n",
    "        df_grouped = df_grouped.withColumn(column, F.round(F.col(column), 1))\n",
    "\n",
    "    return df_grouped\n",
    "\n",
    "\n",
    "######### Text Processing Functions ########\n",
    "@udf(\"string\")\n",
    "def normalize_text(text):\n",
    "    \"\"\"Helper function to normalize text data to ASCII and lower case, removing spaces\n",
    "\n",
    "    Args:\n",
    "        text (string): the string that needs to be normalized\n",
    "\n",
    "    Returns:\n",
    "        text (string): cleaned up string\n",
    "\n",
    "    \"\"\"\n",
    "    regex = r\"[^a-zA-Z0-9]+\"\n",
    "\n",
    "    if text is not None:\n",
    "\n",
    "        text = str(text)\n",
    "        text = text.lower()\n",
    "        text = re.sub(regex, \" \", text)\n",
    "        text = text.strip()\n",
    "        text = str(\n",
    "            unicodedata.normalize(\"NFKD\", text).encode(\"ASCII\", \"ignore\"), \"utf-8\"\n",
    "        )\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_null_columns(df, normalize=False):\n",
    "    \"\"\"Helper function to print the number of null records for each column of a PySpark DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pyspark.sql.dataframe.DataFrame): a PySpark Dataframe object\n",
    "\n",
    "    Returns:\n",
    "        None -> prints to standard out\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        total = df.count()\n",
    "\n",
    "        df_nulls = df.select(\n",
    "            [\n",
    "                (F.sum(F.when(F.col(column).isNull(), 1).otherwise(0)) / total).alias(\n",
    "                    column\n",
    "                )\n",
    "                for column in df.columns\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        df_nulls = df.select(\n",
    "            [\n",
    "                F.sum(F.when(F.col(column).isNull(), 1).otherwise(0)).alias(column)\n",
    "                for column in df.columns\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # displaying the results to standard out\n",
    "    df_nulls.show(1, truncate=False, vertical=True)\n",
    "\n",
    "\n",
    "@udf(\"boolean\")\n",
    "def is_set_or_pack(text):\n",
    "\n",
    "    # description entries to match:\n",
    "    set_descriptions = {\"set\", \"set of\", \"pack\", \"pack of\", \"box\", \"box of\"}\n",
    "\n",
    "    if text is not None:\n",
    "        text = str(text)\n",
    "\n",
    "        if text in set_descriptions:\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "@udf(\"integer\")\n",
    "def get_unit_size(text):\n",
    "\n",
    "    if text is not None:\n",
    "        check_if_digit = len(re.findall(r\"(\\d+)\", text)) > 0\n",
    "\n",
    "        if check_if_digit:\n",
    "            set_size = int(re.findall(r\"(\\d+)\", text)[0])\n",
    "            return set_size\n",
    "\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "@udf(\"boolean\")\n",
    "def has_non_digits_only(text):\n",
    "    \"\"\"Function to match entries in the dataset that are purely non-digit characters\n",
    "\n",
    "    Args:\n",
    "        text (str): string containing the invoice code\n",
    "\n",
    "    Returns:\n",
    "        boolean: whether the text contains non-digit characters and is not related to cancellations\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if text is not None:\n",
    "        condition = all(character.isalpha() for character in text)\n",
    "\n",
    "        if condition:\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading and Inspecting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# loading the raw dataset:\\ndf_raw = spark.read.option(\\\"header\\\", True).csv(\\\"../data/raw/Ecommerce.csv\\\")\";\n",
       "                var nbb_formatted_code = \"# loading the raw dataset:\\ndf_raw = spark.read.option(\\\"header\\\", True).csv(\\\"../data/raw/Ecommerce.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading the raw dataset:\n",
    "df_raw = spark.read.option(\"header\", True).csv(\"../data/raw/Ecommerce.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# verifying the data schema:\\ndf_raw.printSchema()\";\n",
       "                var nbb_formatted_code = \"# verifying the data schema:\\ndf_raw.printSchema()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verifying the data schema:\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>InvoiceNo</th><th>StockCode</th><th>Description</th><th>Quantity</th><th>InvoiceDate</th><th>UnitPrice</th><th>CustomerID</th><th>Country</th><th>_c8</th></tr>\n",
       "<tr><td>536365</td><td>85123A</td><td>WHITE HANGING HEA...</td><td>6</td><td>29-Nov-16</td><td>2.55</td><td>17850</td><td>United Kingdom</td><td>null</td></tr>\n",
       "<tr><td>536365</td><td>71053</td><td>WHITE METAL LANTERN</td><td>6</td><td>29-Nov-16</td><td>3.39</td><td>17850</td><td>United Kingdom</td><td>null</td></tr>\n",
       "<tr><td>536365</td><td>84406B</td><td>CREAM CUPID HEART...</td><td>8</td><td>29-Nov-16</td><td>2.75</td><td>17850</td><td>United Kingdom</td><td>null</td></tr>\n",
       "<tr><td>536365</td><td>84029G</td><td>KNITTED UNION FLA...</td><td>6</td><td>29-Nov-16</td><td>3.39</td><td>17850</td><td>United Kingdom</td><td>null</td></tr>\n",
       "<tr><td>536365</td><td>84029E</td><td>RED WOOLLY HOTTIE...</td><td>6</td><td>29-Nov-16</td><td>3.39</td><td>17850</td><td>United Kingdom</td><td>null</td></tr>\n",
       "</table>\n",
       "only showing top 5 rows\n"
      ],
      "text/plain": [
       "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+----+\n",
       "|InvoiceNo|StockCode|         Description|Quantity|InvoiceDate|UnitPrice|CustomerID|       Country| _c8|\n",
       "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+----+\n",
       "|   536365|   85123A|WHITE HANGING HEA...|       6|  29-Nov-16|     2.55|     17850|United Kingdom|null|\n",
       "|   536365|    71053| WHITE METAL LANTERN|       6|  29-Nov-16|     3.39|     17850|United Kingdom|null|\n",
       "|   536365|   84406B|CREAM CUPID HEART...|       8|  29-Nov-16|     2.75|     17850|United Kingdom|null|\n",
       "|   536365|   84029G|KNITTED UNION FLA...|       6|  29-Nov-16|     3.39|     17850|United Kingdom|null|\n",
       "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|  29-Nov-16|     3.39|     17850|United Kingdom|null|\n",
       "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+----+\n",
       "only showing top 5 rows"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# displaying some records from the data:\\ndf_raw\";\n",
       "                var nbb_formatted_code = \"# displaying some records from the data:\\ndf_raw\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying some records from the data:\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------\n",
      " InvoiceNo   | 0      \n",
      " StockCode   | 0      \n",
      " Description | 1454   \n",
      " Quantity    | 0      \n",
      " InvoiceDate | 0      \n",
      " UnitPrice   | 0      \n",
      " CustomerID  | 135080 \n",
      " Country     | 0      \n",
      " _c8         | 541909 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# counting nulls in the dataframe:\\nget_null_columns(df_raw)\";\n",
       "                var nbb_formatted_code = \"# counting nulls in the dataframe:\\nget_null_columns(df_raw)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# counting nulls in the dataframe:\n",
    "get_null_columns(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are changes I mapped out for this dataset:\n",
    "\n",
    "1. Snake case column names for easier manipulation; \n",
    "2. Remove unnecessary columns (i.e: `Unnamed: 8`);\n",
    "3. Convert `InvoiceDate` to a `DateTime` object;\n",
    "4. Convert `CustomerID` to `int` (it is an unique code);\n",
    "5. Normalizing all text data in `Description` and `Country` to remove unnecessary characters;\n",
    "6. Handling the missing values in `CustomerID`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# dropping the unnecessary column (last one):\\ndf_raw = df_raw.drop(\\\"_c8\\\")\";\n",
       "                var nbb_formatted_code = \"# dropping the unnecessary column (last one):\\ndf_raw = df_raw.drop(\\\"_c8\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dropping the unnecessary column (last one):\n",
    "df_raw = df_raw.drop(\"_c8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Fixing Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# fixing column names with snake casing:\\nfor col in df_raw.columns:\\n    df_raw = df_raw.withColumnRenamed(col, inflection.underscore(col))\";\n",
       "                var nbb_formatted_code = \"# fixing column names with snake casing:\\nfor col in df_raw.columns:\\n    df_raw = df_raw.withColumnRenamed(col, inflection.underscore(col))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fixing column names with snake casing:\n",
    "for col in df_raw.columns:\n",
    "    df_raw = df_raw.withColumnRenamed(col, inflection.underscore(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Fixing Data Types and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# converting invoice_date to date:\\ndf_raw = df_raw.withColumn(\\n    \\\"invoice_date\\\",\\n    F.from_unixtime(F.unix_timestamp(\\\"invoice_date\\\", \\\"dd-MMM-yy\\\")).cast(\\\"date\\\"),\\n)\";\n",
       "                var nbb_formatted_code = \"# converting invoice_date to date:\\ndf_raw = df_raw.withColumn(\\n    \\\"invoice_date\\\",\\n    F.from_unixtime(F.unix_timestamp(\\\"invoice_date\\\", \\\"dd-MMM-yy\\\")).cast(\\\"date\\\"),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting invoice_date to date:\n",
    "df_raw = df_raw.withColumn(\n",
    "    \"invoice_date\",\n",
    "    F.from_unixtime(F.unix_timestamp(\"invoice_date\", \"dd-MMM-yy\")).cast(\"date\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# converting customer id to an integer:\\ndf_raw = df_raw.withColumn(\\\"customer_id\\\", F.col(\\\"customer_id\\\").cast(\\\"int\\\"))\";\n",
       "                var nbb_formatted_code = \"# converting customer id to an integer:\\ndf_raw = df_raw.withColumn(\\\"customer_id\\\", F.col(\\\"customer_id\\\").cast(\\\"int\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting customer id to an integer:\n",
    "df_raw = df_raw.withColumn(\"customer_id\", F.col(\"customer_id\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# handling missing values and customer ids:\\ndf_raw = df_raw.withColumn(\\n    \\\"customer_id\\\",\\n    F.when(\\n        F.col(\\\"customer_id\\\").isNull(), -1\\n    ).otherwise(  # missing values will be given a -1 indicator\\n        F.col(\\\"customer_id\\\")\\n    ),\\n)\";\n",
       "                var nbb_formatted_code = \"# handling missing values and customer ids:\\ndf_raw = df_raw.withColumn(\\n    \\\"customer_id\\\",\\n    F.when(\\n        F.col(\\\"customer_id\\\").isNull(), -1\\n    ).otherwise(  # missing values will be given a -1 indicator\\n        F.col(\\\"customer_id\\\")\\n    ),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# handling missing values and customer ids:\n",
    "df_raw = df_raw.withColumn(\n",
    "    \"customer_id\",\n",
    "    F.when(\n",
    "        F.col(\"customer_id\").isNull(), -1\n",
    "    ).otherwise(  # missing values will be given a -1 indicator\n",
    "        F.col(\"customer_id\")\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# adding a indicator for missing customer id:\\ndf_raw = df_raw.withColumn(\\n    \\\"is_missing_customer_id\\\", F.when(df_raw.customer_id == -1, True).otherwise(False)\\n)\";\n",
       "                var nbb_formatted_code = \"# adding a indicator for missing customer id:\\ndf_raw = df_raw.withColumn(\\n    \\\"is_missing_customer_id\\\", F.when(df_raw.customer_id == -1, True).otherwise(False)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding a indicator for missing customer id:\n",
    "df_raw = df_raw.withColumn(\n",
    "    \"is_missing_customer_id\", F.when(df_raw.customer_id == -1, True).otherwise(False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Normalizing Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# applying the normalize_text UDF previously defined to the columns listed:\\ncols_to_process = [\\\"country\\\", \\\"description\\\"]\\n\\nfor column in cols_to_process:\\n    df_raw = df_raw.withColumn(column, normalize_text(F.col(column)))\";\n",
       "                var nbb_formatted_code = \"# applying the normalize_text UDF previously defined to the columns listed:\\ncols_to_process = [\\\"country\\\", \\\"description\\\"]\\n\\nfor column in cols_to_process:\\n    df_raw = df_raw.withColumn(column, normalize_text(F.col(column)))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# applying the normalize_text UDF previously defined to the columns listed:\n",
    "cols_to_process = [\"country\", \"description\"]\n",
    "\n",
    "for column in cols_to_process:\n",
    "    df_raw = df_raw.withColumn(column, normalize_text(F.col(column)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Raw Data Feature Prepation\n",
    "The E-commerce dataset I am working with, as the dataset description suggests, is from an *website that sells primarily gifts*. I will split in a few different ways, as the outline below suggests. These `entities` are: \n",
    "\n",
    "1. `Customer`: features related to the customer, such as total time as a customer, time since last purchase, favorite products;\n",
    "2. `Invoice`: features related to a single order, such as basket size (number of distinct items), size of the order, total paid;\"\n",
    "3. `Product`: features related to a specific product, such as last time sold, total sold at a specific period of time;\n",
    "\n",
    "The schema I envisioned to this dataset can be found in the figure below.\n",
    "\n",
    "<img src=\"../reports/figures/Ecommerce Schema.png\" alt = \"Ecommerce Dataset\" style = \"width:1182px; height=702px;\">\n",
    "\n",
    "I will add features to the raw dataset at the `invoice-item` granularity it is originally written to so that we can build the necessary views later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Datetime attribute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# adding date-time attributes to invoice entries:\\ndf_raw = get_datetime_features(df_raw, \\\"invoice_date\\\")\";\n",
       "                var nbb_formatted_code = \"# adding date-time attributes to invoice entries:\\ndf_raw = get_datetime_features(df_raw, \\\"invoice_date\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding date-time attributes to invoice entries:\n",
    "df_raw = get_datetime_features(df_raw, \"invoice_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Holiday-related features\n",
    "Given that the context of this E-commerce is that of a place that sells mostly gifts and novelty items, it is quite pertinent that we address the seasonal variations and trends related to commemorative dates. With that in mind, we will add features related to the context of holidays in the UK (the main location of the website, where the majority of customers are) as well as some global holidays.\n",
    "\n",
    "Let's first clarify what I am considering a Commercial Holiday and a Bank Holiday:\n",
    "\n",
    "1. **Commercial Holidays**: dates in which (most of the times) there aren't any interruptions to services (i.e banks), but that have some kind of stimulus for consumption. Purchases that are stimulated by these dates occur either on the specific day (such as Black Friday) or very close to it;\n",
    "2. **Bank Holidays**: dates in which services are interrupted and people often don't work. Purchases stimulated by these dates usually occur earlier (i.e Christmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# defining a dictionary of commercial holidays:\\ncommercial_holidays = {\\n    \\\"Black Friday 2017\\\": pd.to_datetime(\\\"2017-11-24\\\"),\\n    \\\"Mother's Day  2017\\\": pd.to_datetime(\\\"2017-03-26\\\"),\\n    \\\"Father's Day 2017\\\": pd.to_datetime(\\\"2017-06-18\\\"),\\n    \\\"Valentine's Day 2017\\\": pd.to_datetime(\\\"2017-02-14\\\"),\\n    \\\"Boxing Day 2016\\\": pd.to_datetime(\\\"2016-12-26\\\"),\\n    \\\"Boxing Day 2017\\\": pd.to_datetime(\\\"2017-12-26\\\"),\\n    \\\"New Year's 2017\\\": pd.to_datetime(\\\"2017-01-01\\\"),\\n    \\\"Saint Patrick's Day\\\": pd.to_datetime(\\\"2017-03-17\\\"),\\n}\\n\\nbank_holidays = {\\n    \\\"Christmas 2016\\\": pd.to_datetime(\\\"2016-12-25\\\"),\\n    \\\"Christmas 2017\\\": pd.to_datetime(\\\"2017-12-25\\\"),\\n    \\\"New Year's 2017\\\": pd.to_datetime(\\\"2017-01-01\\\"),\\n    \\\"Saint Patrick's Day\\\": pd.to_datetime(\\\"2017-03-17\\\"),\\n    \\\"Hogmanay 2016\\\": pd.to_datetime(\\\"2016-12-31\\\"),\\n    \\\"Hogmanay 2017\\\": pd.to_datetime(\\\"2017-12-31\\\"),\\n    \\\"Easter 2017\\\": pd.to_datetime(\\\"2017-04-16\\\"),\\n}\\n\\n# holiday dates become:\\ncommercial_dates = set(commercial_holidays.values())\\nbank_dates = set(bank_holidays.values())\\n\\n# weeks of year and months that contain holidays:\\nweeks_commercial_dates = set([date.weekofyear for date in commercial_dates])\\nmonths_commercial_dates = set([date.month for date in commercial_dates])\\nweeks_bank_dates = set([date.weekofyear for date in bank_dates])\\nmonths_bank_dates = set([date.month for date in bank_dates])\";\n",
       "                var nbb_formatted_code = \"# defining a dictionary of commercial holidays:\\ncommercial_holidays = {\\n    \\\"Black Friday 2017\\\": pd.to_datetime(\\\"2017-11-24\\\"),\\n    \\\"Mother's Day  2017\\\": pd.to_datetime(\\\"2017-03-26\\\"),\\n    \\\"Father's Day 2017\\\": pd.to_datetime(\\\"2017-06-18\\\"),\\n    \\\"Valentine's Day 2017\\\": pd.to_datetime(\\\"2017-02-14\\\"),\\n    \\\"Boxing Day 2016\\\": pd.to_datetime(\\\"2016-12-26\\\"),\\n    \\\"Boxing Day 2017\\\": pd.to_datetime(\\\"2017-12-26\\\"),\\n    \\\"New Year's 2017\\\": pd.to_datetime(\\\"2017-01-01\\\"),\\n    \\\"Saint Patrick's Day\\\": pd.to_datetime(\\\"2017-03-17\\\"),\\n}\\n\\nbank_holidays = {\\n    \\\"Christmas 2016\\\": pd.to_datetime(\\\"2016-12-25\\\"),\\n    \\\"Christmas 2017\\\": pd.to_datetime(\\\"2017-12-25\\\"),\\n    \\\"New Year's 2017\\\": pd.to_datetime(\\\"2017-01-01\\\"),\\n    \\\"Saint Patrick's Day\\\": pd.to_datetime(\\\"2017-03-17\\\"),\\n    \\\"Hogmanay 2016\\\": pd.to_datetime(\\\"2016-12-31\\\"),\\n    \\\"Hogmanay 2017\\\": pd.to_datetime(\\\"2017-12-31\\\"),\\n    \\\"Easter 2017\\\": pd.to_datetime(\\\"2017-04-16\\\"),\\n}\\n\\n# holiday dates become:\\ncommercial_dates = set(commercial_holidays.values())\\nbank_dates = set(bank_holidays.values())\\n\\n# weeks of year and months that contain holidays:\\nweeks_commercial_dates = set([date.weekofyear for date in commercial_dates])\\nmonths_commercial_dates = set([date.month for date in commercial_dates])\\nweeks_bank_dates = set([date.weekofyear for date in bank_dates])\\nmonths_bank_dates = set([date.month for date in bank_dates])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining a dictionary of commercial holidays:\n",
    "commercial_holidays = {\n",
    "    \"Black Friday 2017\": pd.to_datetime(\"2017-11-24\"),\n",
    "    \"Mother's Day  2017\": pd.to_datetime(\"2017-03-26\"),\n",
    "    \"Father's Day 2017\": pd.to_datetime(\"2017-06-18\"),\n",
    "    \"Valentine's Day 2017\": pd.to_datetime(\"2017-02-14\"),\n",
    "    \"Boxing Day 2016\": pd.to_datetime(\"2016-12-26\"),\n",
    "    \"Boxing Day 2017\": pd.to_datetime(\"2017-12-26\"),\n",
    "    \"New Year's 2017\": pd.to_datetime(\"2017-01-01\"),\n",
    "    \"Saint Patrick's Day\": pd.to_datetime(\"2017-03-17\"),\n",
    "}\n",
    "\n",
    "bank_holidays = {\n",
    "    \"Christmas 2016\": pd.to_datetime(\"2016-12-25\"),\n",
    "    \"Christmas 2017\": pd.to_datetime(\"2017-12-25\"),\n",
    "    \"New Year's 2017\": pd.to_datetime(\"2017-01-01\"),\n",
    "    \"Saint Patrick's Day\": pd.to_datetime(\"2017-03-17\"),\n",
    "    \"Hogmanay 2016\": pd.to_datetime(\"2016-12-31\"),\n",
    "    \"Hogmanay 2017\": pd.to_datetime(\"2017-12-31\"),\n",
    "    \"Easter 2017\": pd.to_datetime(\"2017-04-16\"),\n",
    "}\n",
    "\n",
    "# holiday dates become:\n",
    "commercial_dates = set(commercial_holidays.values())\n",
    "bank_dates = set(bank_holidays.values())\n",
    "\n",
    "# weeks of year and months that contain holidays:\n",
    "weeks_commercial_dates = set([date.weekofyear for date in commercial_dates])\n",
    "months_commercial_dates = set([date.month for date in commercial_dates])\n",
    "weeks_bank_dates = set([date.weekofyear for date in bank_dates])\n",
    "months_bank_dates = set([date.month for date in bank_dates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# adding boolean flags for the commercial dates:\\ndf_raw = df_raw.withColumn(\\n    \\\"is_commercial_holiday\\\", F.col(\\\"invoice_date\\\").isin(commercial_dates)\\n)\\n\\ndf_raw = df_raw.withColumn(\\n    \\\"is_commercial_holiday_week\\\", F.col(\\\"week_of_year\\\").isin(weeks_commercial_dates)\\n)\\n\\ndf_raw = df_raw.withColumn(\\n    \\\"is_commercial_holiday_month\\\", F.col(\\\"month\\\").isin(months_commercial_dates)\\n)\";\n",
       "                var nbb_formatted_code = \"# adding boolean flags for the commercial dates:\\ndf_raw = df_raw.withColumn(\\n    \\\"is_commercial_holiday\\\", F.col(\\\"invoice_date\\\").isin(commercial_dates)\\n)\\n\\ndf_raw = df_raw.withColumn(\\n    \\\"is_commercial_holiday_week\\\", F.col(\\\"week_of_year\\\").isin(weeks_commercial_dates)\\n)\\n\\ndf_raw = df_raw.withColumn(\\n    \\\"is_commercial_holiday_month\\\", F.col(\\\"month\\\").isin(months_commercial_dates)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding boolean flags for the commercial dates:\n",
    "df_raw = df_raw.withColumn(\n",
    "    \"is_commercial_holiday\", F.col(\"invoice_date\").isin(commercial_dates)\n",
    ")\n",
    "\n",
    "df_raw = df_raw.withColumn(\n",
    "    \"is_commercial_holiday_week\", F.col(\"week_of_year\").isin(weeks_commercial_dates)\n",
    ")\n",
    "\n",
    "df_raw = df_raw.withColumn(\n",
    "    \"is_commercial_holiday_month\", F.col(\"month\").isin(months_commercial_dates)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# adding boolean flags for the bank dates:\\ndf_raw = (df_raw\\n             .withColumn('is_bank_holiday', \\n                         F.col('invoice_date')\\n                          .isin(bank_dates)))\\n\\ndf_raw = (df_raw\\n             .withColumn('is_bank_holiday_week', \\n                         F.col('week_of_year')\\n                          .isin(weeks_bank_dates)))\\n\\ndf_raw = (df_raw\\n             .withColumn('is_bank_holiday_month', \\n                         F.col('month')\\n                          .isin(months_bank_dates)))\";\n",
       "                var nbb_formatted_code = \"# adding boolean flags for the bank dates:\\ndf_raw = df_raw.withColumn(\\\"is_bank_holiday\\\", F.col(\\\"invoice_date\\\").isin(bank_dates))\\n\\ndf_raw = df_raw.withColumn(\\n    \\\"is_bank_holiday_week\\\", F.col(\\\"week_of_year\\\").isin(weeks_bank_dates)\\n)\\n\\ndf_raw = df_raw.withColumn(\\n    \\\"is_bank_holiday_month\\\", F.col(\\\"month\\\").isin(months_bank_dates)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding boolean flags for the bank dates:\n",
    "df_raw = df_raw.withColumn(\"is_bank_holiday\", F.col(\"invoice_date\").isin(bank_dates))\n",
    "\n",
    "df_raw = df_raw.withColumn(\n",
    "    \"is_bank_holiday_week\", F.col(\"week_of_year\").isin(weeks_bank_dates)\n",
    ")\n",
    "\n",
    "df_raw = df_raw.withColumn(\n",
    "    \"is_bank_holiday_month\", F.col(\"month\").isin(months_bank_dates)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Returns, Cancellations and Free items\n",
    "There still some kinds of behaviors we would like to capture, such if the order/invoice refers to a cancellation. According to a similar dataset in UCI Machine Learning repository, we can differentiate these with invoice numbers that start with a C.\n",
    "\n",
    "Also, we might need to address the items that are freebies (have unit price = 0) as another feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# addinng handles for cancellations:\\ndf_raw = (df_raw\\n             .withColumn('is_cancelled',\\n                         F.col('invoice_no')\\n                          .startswith('C')))\";\n",
       "                var nbb_formatted_code = \"# addinng handles for cancellations:\\ndf_raw = df_raw.withColumn(\\\"is_cancelled\\\", F.col(\\\"invoice_no\\\").startswith(\\\"C\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# addinng handles for cancellations:\n",
    "df_raw = df_raw.withColumn(\"is_cancelled\", F.col(\"invoice_no\").startswith(\"C\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# adding boolean handles for free items (price == 0)\\ndf_raw = (df_raw\\n             .withColumn('is_return', \\n                         ((df_raw.quantity < 0)\\n                          & (df_raw.is_cancelled == False))))\";\n",
       "                var nbb_formatted_code = \"# adding boolean handles for free items (price == 0)\\ndf_raw = df_raw.withColumn(\\n    \\\"is_return\\\", ((df_raw.quantity < 0) & (df_raw.is_cancelled == False))\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding boolean handles for free items (price == 0)\n",
    "df_raw = df_raw.withColumn(\n",
    "    \"is_return\", ((df_raw.quantity < 0) & (df_raw.is_cancelled == False))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# adding free items:\\ndf_raw = (df_raw\\n             .withColumn('is_free_item', \\n                            ((df_raw.unit_price == 0) \\n                             & (df_raw.is_cancelled == False))))\";\n",
       "                var nbb_formatted_code = \"# adding free items:\\ndf_raw = df_raw.withColumn(\\n    \\\"is_free_item\\\", ((df_raw.unit_price == 0) & (df_raw.is_cancelled == False))\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding free items:\n",
    "df_raw = df_raw.withColumn(\n",
    "    \"is_free_item\", ((df_raw.unit_price == 0) & (df_raw.is_cancelled == False))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Price features\n",
    "We will add the total price paid for an item in the invoice to the dataset and address issues with different prices being associated with specific products. Since we don't have direct flags that indicate that a certain invoice-item-product combination contains discounts, I will use an heuristic to address it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# adding the total paid per item:\\ndf_raw = (df_raw\\n             .withColumn('total_item_price', \\n                         F.col('unit_price') * F.col('quantity')))\";\n",
       "                var nbb_formatted_code = \"# adding the total paid per item:\\ndf_raw = df_raw.withColumn(\\\"total_item_price\\\", F.col(\\\"unit_price\\\") * F.col(\\\"quantity\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding the total paid per item:\n",
    "df_raw = df_raw.withColumn(\"total_item_price\", F.col(\"unit_price\") * F.col(\"quantity\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# grouping products to grab the most common price:\\ndf_products = (df_raw\\n                  .groupby(['description', 'unit_price'])\\n                  .count())\";\n",
       "                var nbb_formatted_code = \"# grouping products to grab the most common price:\\ndf_products = df_raw.groupby([\\\"description\\\", \\\"unit_price\\\"]).count()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grouping products to grab the most common price:\n",
    "df_products = df_raw.groupby([\"description\", \"unit_price\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# setting a window function to get the most common value:\\nmode_window = (Window\\n                   .partitionBy(\\\"description\\\")\\n                   .orderBy(F.desc(\\\"count\\\")))\\n\\n# adding the ranking to the dataframe:\\ndf_products = (df_products\\n                  .withColumn('row_idx', \\n                              F.row_number()\\n                               .over(mode_window)))\\n\\n# retrieving only the most common item:\\ndf_products = (df_products\\n                  .filter(df_products.row_idx == 1))\\n\\ndf_products = (df_products\\n                  .withColumnRenamed('unit_price', \\n                                    'retail_price')\\n                  .select('description', 'retail_price'))\";\n",
       "                var nbb_formatted_code = \"# setting a window function to get the most common value:\\nmode_window = Window.partitionBy(\\\"description\\\").orderBy(F.desc(\\\"count\\\"))\\n\\n# adding the ranking to the dataframe:\\ndf_products = df_products.withColumn(\\\"row_idx\\\", F.row_number().over(mode_window))\\n\\n# retrieving only the most common item:\\ndf_products = df_products.filter(df_products.row_idx == 1)\\n\\ndf_products = df_products.withColumnRenamed(\\\"unit_price\\\", \\\"retail_price\\\").select(\\n    \\\"description\\\", \\\"retail_price\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setting a window function to get the most common value:\n",
    "mode_window = Window.partitionBy(\"description\").orderBy(F.desc(\"count\"))\n",
    "\n",
    "# adding the ranking to the dataframe:\n",
    "df_products = df_products.withColumn(\"row_idx\", F.row_number().over(mode_window))\n",
    "\n",
    "# retrieving only the most common item:\n",
    "df_products = df_products.filter(df_products.row_idx == 1)\n",
    "\n",
    "df_products = df_products.withColumnRenamed(\"unit_price\", \"retail_price\").select(\n",
    "    \"description\", \"retail_price\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# retrieving product price statistics:\\ndf_product_stats = (df_raw\\n                      .groupby('description')\\n                      .agg(\\n                          F.min(F.abs(F.col('unit_price'))).alias('min_unit_price'),\\n                          F.avg(F.abs(F.col('unit_price'))).alias('avg_unit_price'),\\n                          F.percentile_approx(F.abs(F.col('unit_price')), 0.5).alias('median_unit_price'),\\n                          F.max(F.abs(F.col('unit_price'))).alias('max_unit_price')\\n                      ))\\n\\n# joining the datasets:\\ndf_products_full = (df_products\\n                       .join(df_product_stats,\\n                             how = 'inner',\\n                             on = ['description']))\\n\\n# dropping the duplicates;\\ndf_products_full = (df_products_full\\n                       .drop_duplicates())\";\n",
       "                var nbb_formatted_code = \"# retrieving product price statistics:\\ndf_product_stats = df_raw.groupby(\\\"description\\\").agg(\\n    F.min(F.abs(F.col(\\\"unit_price\\\"))).alias(\\\"min_unit_price\\\"),\\n    F.avg(F.abs(F.col(\\\"unit_price\\\"))).alias(\\\"avg_unit_price\\\"),\\n    F.percentile_approx(F.abs(F.col(\\\"unit_price\\\")), 0.5).alias(\\\"median_unit_price\\\"),\\n    F.max(F.abs(F.col(\\\"unit_price\\\"))).alias(\\\"max_unit_price\\\"),\\n)\\n\\n# joining the datasets:\\ndf_products_full = df_products.join(df_product_stats, how=\\\"inner\\\", on=[\\\"description\\\"])\\n\\n# dropping the duplicates;\\ndf_products_full = df_products_full.drop_duplicates()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retrieving product price statistics:\n",
    "df_product_stats = df_raw.groupby(\"description\").agg(\n",
    "    F.min(F.abs(F.col(\"unit_price\"))).alias(\"min_unit_price\"),\n",
    "    F.avg(F.abs(F.col(\"unit_price\"))).alias(\"avg_unit_price\"),\n",
    "    F.percentile_approx(F.abs(F.col(\"unit_price\")), 0.5).alias(\"median_unit_price\"),\n",
    "    F.max(F.abs(F.col(\"unit_price\"))).alias(\"max_unit_price\"),\n",
    ")\n",
    "\n",
    "# joining the datasets:\n",
    "df_products_full = df_products.join(df_product_stats, how=\"inner\", on=[\"description\"])\n",
    "\n",
    "# dropping the duplicates;\n",
    "df_products_full = df_products_full.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# adding price statistics to the main dataframe:\\ndf_raw = (df_raw\\n             .join(df_products_full,\\n                   on = ['description'],\\n                   how = 'left'))\";\n",
       "                var nbb_formatted_code = \"# adding price statistics to the main dataframe:\\ndf_raw = df_raw.join(df_products_full, on=[\\\"description\\\"], how=\\\"left\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding price statistics to the main dataframe:\n",
    "df_raw = df_raw.join(df_products_full, on=[\"description\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# adding a boolean handle to denote discounts:\\ndf_raw = (df_raw\\n              .withColumn('is_discounted_item', \\n                          (df_raw.unit_price < df_raw.retail_price)))\";\n",
       "                var nbb_formatted_code = \"# adding a boolean handle to denote discounts:\\ndf_raw = df_raw.withColumn(\\n    \\\"is_discounted_item\\\", (df_raw.unit_price < df_raw.retail_price)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding a boolean handle to denote discounts:\n",
    "df_raw = df_raw.withColumn(\n",
    "    \"is_discounted_item\", (df_raw.unit_price < df_raw.retail_price)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Addressing non-product items\n",
    "As we saw, there seems to be some items that are not related to the products themselves. For example, itens related to postage expenses. Removing these might be not as beneficial, so I will figure out a way to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# adding boolean handle for further exploration:\\ndf_raw = (df_raw\\n             .withColumn('has_non_digit',\\n                         has_non_digits_only(F.col('stock_code'))))\";\n",
       "                var nbb_formatted_code = \"# adding boolean handle for further exploration:\\ndf_raw = df_raw.withColumn(\\\"has_non_digit\\\", has_non_digits_only(F.col(\\\"stock_code\\\")))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding boolean handle for further exploration:\n",
    "df_raw = df_raw.withColumn(\"has_non_digit\", has_non_digits_only(F.col(\"stock_code\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>description</th><th>invoice_no</th><th>stock_code</th><th>quantity</th><th>invoice_date</th><th>unit_price</th><th>customer_id</th><th>country</th><th>is_missing_customer_id</th><th>day_of_week</th><th>day_of_month</th><th>day_of_year</th><th>week_of_year</th><th>month</th><th>quarter</th><th>year</th><th>is_commercial_holiday</th><th>is_commercial_holiday_week</th><th>is_commercial_holiday_month</th><th>is_bank_holiday</th><th>is_bank_holiday_week</th><th>is_bank_holiday_month</th><th>is_cancelled</th><th>is_return</th><th>is_free_item</th><th>total_item_price</th><th>retail_price</th><th>min_unit_price</th><th>avg_unit_price</th><th>median_unit_price</th><th>max_unit_price</th><th>is_discounted_item</th><th>has_non_digit</th></tr>\n",
       "<tr><td>discount</td><td>C536379</td><td>D</td><td>-1</td><td>2016-11-29</td><td>27.5</td><td>14527</td><td>united kingdom</td><td>false</td><td>3</td><td>29</td><td>334</td><td>48</td><td>11</td><td>4</td><td>2016</td><td>false</td><td>false</td><td>true</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>false</td><td>-27.5</td><td>11.84</td><td>0.01</td><td>72.48454545454545</td><td>22.97</td><td>1867.86</td><td>false</td><td>true</td></tr>\n",
       "<tr><td>discount</td><td>C537164</td><td>D</td><td>-1</td><td>2016-12-03</td><td>29.29</td><td>14527</td><td>united kingdom</td><td>false</td><td>7</td><td>3</td><td>338</td><td>48</td><td>12</td><td>4</td><td>2016</td><td>false</td><td>false</td><td>true</td><td>false</td><td>false</td><td>true</td><td>true</td><td>false</td><td>false</td><td>-29.29</td><td>11.84</td><td>0.01</td><td>72.48454545454545</td><td>22.97</td><td>1867.86</td><td>false</td><td>true</td></tr>\n",
       "<tr><td>discount</td><td>C537597</td><td>D</td><td>-1</td><td>2016-12-05</td><td>281</td><td>15498</td><td>united kingdom</td><td>false</td><td>2</td><td>5</td><td>340</td><td>49</td><td>12</td><td>4</td><td>2016</td><td>false</td><td>false</td><td>true</td><td>false</td><td>false</td><td>true</td><td>true</td><td>false</td><td>false</td><td>-281.0</td><td>11.84</td><td>0.01</td><td>72.48454545454545</td><td>22.97</td><td>1867.86</td><td>false</td><td>true</td></tr>\n",
       "<tr><td>discount</td><td>C537857</td><td>D</td><td>-1</td><td>2016-12-06</td><td>267.12</td><td>17340</td><td>united kingdom</td><td>false</td><td>3</td><td>6</td><td>341</td><td>49</td><td>12</td><td>4</td><td>2016</td><td>false</td><td>false</td><td>true</td><td>false</td><td>false</td><td>true</td><td>true</td><td>false</td><td>false</td><td>-267.12</td><td>11.84</td><td>0.01</td><td>72.48454545454545</td><td>22.97</td><td>1867.86</td><td>false</td><td>true</td></tr>\n",
       "<tr><td>discount</td><td>C538897</td><td>D</td><td>-1</td><td>2016-12-13</td><td>5.76</td><td>16422</td><td>united kingdom</td><td>false</td><td>3</td><td>13</td><td>348</td><td>50</td><td>12</td><td>4</td><td>2016</td><td>false</td><td>false</td><td>true</td><td>false</td><td>false</td><td>true</td><td>true</td><td>false</td><td>false</td><td>-5.76</td><td>11.84</td><td>0.01</td><td>72.48454545454545</td><td>22.97</td><td>1867.86</td><td>false</td><td>true</td></tr>\n",
       "</table>\n",
       "only showing top 5 rows\n"
      ],
      "text/plain": [
       "+-----------+----------+----------+--------+------------+----------+-----------+--------------+----------------------+-----------+------------+-----------+------------+-----+-------+----+---------------------+--------------------------+---------------------------+---------------+--------------------+---------------------+------------+---------+------------+----------------+------------+--------------+-----------------+-----------------+--------------+------------------+-------------+\n",
       "|description|invoice_no|stock_code|quantity|invoice_date|unit_price|customer_id|       country|is_missing_customer_id|day_of_week|day_of_month|day_of_year|week_of_year|month|quarter|year|is_commercial_holiday|is_commercial_holiday_week|is_commercial_holiday_month|is_bank_holiday|is_bank_holiday_week|is_bank_holiday_month|is_cancelled|is_return|is_free_item|total_item_price|retail_price|min_unit_price|   avg_unit_price|median_unit_price|max_unit_price|is_discounted_item|has_non_digit|\n",
       "+-----------+----------+----------+--------+------------+----------+-----------+--------------+----------------------+-----------+------------+-----------+------------+-----+-------+----+---------------------+--------------------------+---------------------------+---------------+--------------------+---------------------+------------+---------+------------+----------------+------------+--------------+-----------------+-----------------+--------------+------------------+-------------+\n",
       "|   discount|   C536379|         D|      -1|  2016-11-29|      27.5|      14527|united kingdom|                 false|          3|          29|        334|          48|   11|      4|2016|                false|                     false|                       true|          false|               false|                false|        true|    false|       false|           -27.5|       11.84|          0.01|72.48454545454545|            22.97|       1867.86|             false|         true|\n",
       "|   discount|   C537164|         D|      -1|  2016-12-03|     29.29|      14527|united kingdom|                 false|          7|           3|        338|          48|   12|      4|2016|                false|                     false|                       true|          false|               false|                 true|        true|    false|       false|          -29.29|       11.84|          0.01|72.48454545454545|            22.97|       1867.86|             false|         true|\n",
       "|   discount|   C537597|         D|      -1|  2016-12-05|       281|      15498|united kingdom|                 false|          2|           5|        340|          49|   12|      4|2016|                false|                     false|                       true|          false|               false|                 true|        true|    false|       false|          -281.0|       11.84|          0.01|72.48454545454545|            22.97|       1867.86|             false|         true|\n",
       "|   discount|   C537857|         D|      -1|  2016-12-06|    267.12|      17340|united kingdom|                 false|          3|           6|        341|          49|   12|      4|2016|                false|                     false|                       true|          false|               false|                 true|        true|    false|       false|         -267.12|       11.84|          0.01|72.48454545454545|            22.97|       1867.86|             false|         true|\n",
       "|   discount|   C538897|         D|      -1|  2016-12-13|      5.76|      16422|united kingdom|                 false|          3|          13|        348|          50|   12|      4|2016|                false|                     false|                       true|          false|               false|                 true|        true|    false|       false|           -5.76|       11.84|          0.01|72.48454545454545|            22.97|       1867.86|             false|         true|\n",
       "+-----------+----------+----------+--------+------------+----------+-----------+--------------+----------------------+-----------+------------+-----------+------------+-----+-------+----+---------------------+--------------------------+---------------------------+---------------+--------------------+---------------------+------------+---------+------------+----------------+------------+--------------+-----------------+-----------------+--------------+------------------+-------------+\n",
       "only showing top 5 rows"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# visualizing some of the results:\\ndf_raw.filter(df_raw.has_non_digit == True)\";\n",
       "                var nbb_formatted_code = \"# visualizing some of the results:\\ndf_raw.filter(df_raw.has_non_digit == True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing some of the results:\n",
    "df_raw.filter(df_raw.has_non_digit == True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there are items associated with distinct categories:\n",
    "1. Postage and packaging costs (`POST`, `DOT`, `PADS`, `DCGSSGRIL` and `DCGSSBOY`);\n",
    "2. Manuals (`M`);\n",
    "3. Discounts and Samples (`D`, `S`);\n",
    "4. Fees (`AMAZONFEE`);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# generating features regarding theses items:\\npostage = {\\n    'POST',\\n    'DOT',\\n    'PADS',\\n    'DCGSSGRIL',\\n    'DCGSSBOY'\\n}\\n\\nmanuals = {\\n    'M'\\n}\\n\\ndiscounts = {\\n    'D',\\n    'S'\\n}\\n\\nfees = {\\n    'AMAZONFEE'\\n}\\n\\n## adding the boolean indicators for all the different cases:\\ndf_raw = (df_raw\\n             .withColumn('is_postage', \\n                         F.col('stock_code')\\n                          .isin(postage)))\\n\\ndf_raw = (df_raw\\n             .withColumn('is_manual', \\n                         F.col('stock_code')\\n                          .isin(manuals)))\\n\\ndf_raw = (df_raw\\n             .withColumn('is_discount', \\n                         F.col('stock_code')\\n                          .isin(discounts)))\\n\\ndf_raw = (df_raw\\n             .withColumn('is_fee', \\n                         F.col('stock_code')\\n                          .isin(fees)))\";\n",
       "                var nbb_formatted_code = \"# generating features regarding theses items:\\npostage = {\\\"POST\\\", \\\"DOT\\\", \\\"PADS\\\", \\\"DCGSSGRIL\\\", \\\"DCGSSBOY\\\"}\\n\\nmanuals = {\\\"M\\\"}\\n\\ndiscounts = {\\\"D\\\", \\\"S\\\"}\\n\\nfees = {\\\"AMAZONFEE\\\"}\\n\\n## adding the boolean indicators for all the different cases:\\ndf_raw = df_raw.withColumn(\\\"is_postage\\\", F.col(\\\"stock_code\\\").isin(postage))\\n\\ndf_raw = df_raw.withColumn(\\\"is_manual\\\", F.col(\\\"stock_code\\\").isin(manuals))\\n\\ndf_raw = df_raw.withColumn(\\\"is_discount\\\", F.col(\\\"stock_code\\\").isin(discounts))\\n\\ndf_raw = df_raw.withColumn(\\\"is_fee\\\", F.col(\\\"stock_code\\\").isin(fees))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generating features regarding theses items:\n",
    "postage = {\"POST\", \"DOT\", \"PADS\", \"DCGSSGRIL\", \"DCGSSBOY\"}\n",
    "\n",
    "manuals = {\"M\"}\n",
    "\n",
    "discounts = {\"D\", \"S\"}\n",
    "\n",
    "fees = {\"AMAZONFEE\"}\n",
    "\n",
    "## adding the boolean indicators for all the different cases:\n",
    "df_raw = df_raw.withColumn(\"is_postage\", F.col(\"stock_code\").isin(postage))\n",
    "\n",
    "df_raw = df_raw.withColumn(\"is_manual\", F.col(\"stock_code\").isin(manuals))\n",
    "\n",
    "df_raw = df_raw.withColumn(\"is_discount\", F.col(\"stock_code\").isin(discounts))\n",
    "\n",
    "df_raw = df_raw.withColumn(\"is_fee\", F.col(\"stock_code\").isin(fees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Addressing time to the next holiday\n",
    "Given the context of the dataset, it is important to evaluate the time before certain key dates in the calendar that are commonly associated with gift-giving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# transforming the previously defined sets into a row in the original a smaller dataframe:\\ncommercial_dates_list = list(commercial_dates)\\nbank_dates_list = list(bank_dates)\\n\\n# extracting the invoice dates for each invoice record (this reduces the size of the dataset by removing the item-level granularity)\\ndf_invoice_dates = (df_raw\\n                       .groupby('invoice_no')\\n                       .agg(F.first(F.col('invoice_date'))\\n                             .alias('invoice_date')))\";\n",
       "                var nbb_formatted_code = \"# transforming the previously defined sets into a row in the original a smaller dataframe:\\ncommercial_dates_list = list(commercial_dates)\\nbank_dates_list = list(bank_dates)\\n\\n# extracting the invoice dates for each invoice record (this reduces the size of the dataset by removing the item-level granularity)\\ndf_invoice_dates = df_raw.groupby(\\\"invoice_no\\\").agg(\\n    F.first(F.col(\\\"invoice_date\\\")).alias(\\\"invoice_date\\\")\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# transforming the previously defined sets into a row in the original a smaller dataframe:\n",
    "commercial_dates_list = list(commercial_dates)\n",
    "bank_dates_list = list(bank_dates)\n",
    "\n",
    "# extracting the invoice dates for each invoice record (this reduces the size of the dataset by removing the item-level granularity)\n",
    "df_invoice_dates = df_raw.groupby(\"invoice_no\").agg(\n",
    "    F.first(F.col(\"invoice_date\")).alias(\"invoice_date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"# adding the arrays as temporary columns:\\ndf_commercial_dates = (df_invoice_dates\\n                           .withColumn('commercial_dates', \\n                                       F.array([F.to_date(F.lit(date)) for date in commercial_dates_list])))\\n\\ndf_bank_dates = (df_invoice_dates\\n                       .withColumn('bank_dates', \\n                                   F.array([F.to_date(F.lit(date)) for date in bank_dates_list])))\\n\\n# exploding the columns:\\ndf_commercial_dates = (df_commercial_dates\\n                          .select(df_commercial_dates.invoice_no,\\n                                  df_commercial_dates.invoice_date,\\n                                  F.explode(df_commercial_dates.commercial_dates)\\n                                   .alias('commercial_date')\\n                                 ))\\n\\ndf_bank_dates = (df_bank_dates\\n                          .select(df_bank_dates.invoice_no,\\n                                  df_bank_dates.invoice_date,\\n                                  F.explode(df_bank_dates.bank_dates)\\n                                   .alias('bank_date')\\n                                 ))\";\n",
       "                var nbb_formatted_code = \"# adding the arrays as temporary columns:\\ndf_commercial_dates = df_invoice_dates.withColumn(\\n    \\\"commercial_dates\\\",\\n    F.array([F.to_date(F.lit(date)) for date in commercial_dates_list]),\\n)\\n\\ndf_bank_dates = df_invoice_dates.withColumn(\\n    \\\"bank_dates\\\", F.array([F.to_date(F.lit(date)) for date in bank_dates_list])\\n)\\n\\n# exploding the columns:\\ndf_commercial_dates = df_commercial_dates.select(\\n    df_commercial_dates.invoice_no,\\n    df_commercial_dates.invoice_date,\\n    F.explode(df_commercial_dates.commercial_dates).alias(\\\"commercial_date\\\"),\\n)\\n\\ndf_bank_dates = df_bank_dates.select(\\n    df_bank_dates.invoice_no,\\n    df_bank_dates.invoice_date,\\n    F.explode(df_bank_dates.bank_dates).alias(\\\"bank_date\\\"),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding the arrays as temporary columns:\n",
    "df_commercial_dates = df_invoice_dates.withColumn(\n",
    "    \"commercial_dates\",\n",
    "    F.array([F.to_date(F.lit(date)) for date in commercial_dates_list]),\n",
    ")\n",
    "\n",
    "df_bank_dates = df_invoice_dates.withColumn(\n",
    "    \"bank_dates\", F.array([F.to_date(F.lit(date)) for date in bank_dates_list])\n",
    ")\n",
    "\n",
    "# exploding the columns:\n",
    "df_commercial_dates = df_commercial_dates.select(\n",
    "    df_commercial_dates.invoice_no,\n",
    "    df_commercial_dates.invoice_date,\n",
    "    F.explode(df_commercial_dates.commercial_dates).alias(\"commercial_date\"),\n",
    ")\n",
    "\n",
    "df_bank_dates = df_bank_dates.select(\n",
    "    df_bank_dates.invoice_no,\n",
    "    df_bank_dates.invoice_date,\n",
    "    F.explode(df_bank_dates.bank_dates).alias(\"bank_date\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"# calculating the differences in dates:\\ndf_commercial_dates = (df_commercial_dates\\n                          .withColumn('diff_in_days',\\n                                      F.datediff(\\n                                          df_commercial_dates.commercial_date,\\n                                          df_commercial_dates.invoice_date\\n                                      )))\\n\\ndf_bank_dates = (df_bank_dates\\n                          .withColumn('diff_in_days',\\n                                      F.datediff(\\n                                          df_bank_dates.bank_date,\\n                                          df_bank_dates.invoice_date\\n                                      )))\";\n",
       "                var nbb_formatted_code = \"# calculating the differences in dates:\\ndf_commercial_dates = df_commercial_dates.withColumn(\\n    \\\"diff_in_days\\\",\\n    F.datediff(df_commercial_dates.commercial_date, df_commercial_dates.invoice_date),\\n)\\n\\ndf_bank_dates = df_bank_dates.withColumn(\\n    \\\"diff_in_days\\\", F.datediff(df_bank_dates.bank_date, df_bank_dates.invoice_date)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculating the differences in dates:\n",
    "df_commercial_dates = df_commercial_dates.withColumn(\n",
    "    \"diff_in_days\",\n",
    "    F.datediff(df_commercial_dates.commercial_date, df_commercial_dates.invoice_date),\n",
    ")\n",
    "\n",
    "df_bank_dates = df_bank_dates.withColumn(\n",
    "    \"diff_in_days\", F.datediff(df_bank_dates.bank_date, df_bank_dates.invoice_date)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"# filtering out the negative results:\\ndf_commercial_dates = (df_commercial_dates\\n                          .filter(F.col('diff_in_days') > 0))\\n\\ndf_bank_dates = (df_bank_dates\\n                          .filter(F.col('diff_in_days') > 0))\";\n",
       "                var nbb_formatted_code = \"# filtering out the negative results:\\ndf_commercial_dates = df_commercial_dates.filter(F.col(\\\"diff_in_days\\\") > 0)\\n\\ndf_bank_dates = df_bank_dates.filter(F.col(\\\"diff_in_days\\\") > 0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filtering out the negative results:\n",
    "df_commercial_dates = df_commercial_dates.filter(F.col(\"diff_in_days\") > 0)\n",
    "\n",
    "df_bank_dates = df_bank_dates.filter(F.col(\"diff_in_days\") > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"# filtering out the negative results:\\ndf_commercial_dates = (df_commercial_dates\\n                          .groupby('invoice_no', \\n                                   'invoice_date')\\n                          .agg(\\n                              F.min(F.col('diff_in_days'))\\n                               .alias('days_to_next_commercial_holiday')\\n                          ))\\n\\ndf_bank_dates = (df_bank_dates\\n                          .groupby('invoice_no', \\n                                   'invoice_date')\\n                          .agg(\\n                              F.min(F.col('diff_in_days'))\\n                               .alias('days_to_next_bank_holiday')\\n                          ))\";\n",
       "                var nbb_formatted_code = \"# filtering out the negative results:\\ndf_commercial_dates = df_commercial_dates.groupby(\\\"invoice_no\\\", \\\"invoice_date\\\").agg(\\n    F.min(F.col(\\\"diff_in_days\\\")).alias(\\\"days_to_next_commercial_holiday\\\")\\n)\\n\\ndf_bank_dates = df_bank_dates.groupby(\\\"invoice_no\\\", \\\"invoice_date\\\").agg(\\n    F.min(F.col(\\\"diff_in_days\\\")).alias(\\\"days_to_next_bank_holiday\\\")\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filtering out the negative results:\n",
    "df_commercial_dates = df_commercial_dates.groupby(\"invoice_no\", \"invoice_date\").agg(\n",
    "    F.min(F.col(\"diff_in_days\")).alias(\"days_to_next_commercial_holiday\")\n",
    ")\n",
    "\n",
    "df_bank_dates = df_bank_dates.groupby(\"invoice_no\", \"invoice_date\").agg(\n",
    "    F.min(F.col(\"diff_in_days\")).alias(\"days_to_next_bank_holiday\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"# joining the dataset to the original dataframe:\\ndf_raw = (df_raw\\n             .join(\\n                 df_commercial_dates,\\n                 on = ['invoice_no', 'invoice_date'],\\n                 how = 'left'\\n             ))\\n\\ndf_raw = (df_raw\\n             .join(\\n                 df_bank_dates,\\n                 on = ['invoice_no', 'invoice_date'],\\n                 how = 'left'\\n             ))\";\n",
       "                var nbb_formatted_code = \"# joining the dataset to the original dataframe:\\ndf_raw = df_raw.join(df_commercial_dates, on=[\\\"invoice_no\\\", \\\"invoice_date\\\"], how=\\\"left\\\")\\n\\ndf_raw = df_raw.join(df_bank_dates, on=[\\\"invoice_no\\\", \\\"invoice_date\\\"], how=\\\"left\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# joining the dataset to the original dataframe:\n",
    "df_raw = df_raw.join(df_commercial_dates, on=[\"invoice_no\", \"invoice_date\"], how=\"left\")\n",
    "\n",
    "df_raw = df_raw.join(df_bank_dates, on=[\"invoice_no\", \"invoice_date\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"# verifying the data integrity:\\ndf_raw.count() # should match the same number of the records in the previous dataset\";\n",
       "                var nbb_formatted_code = \"# verifying the data integrity:\\ndf_raw.count()  # should match the same number of the records in the previous dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verifying the data integrity:\n",
    "df_raw.count()  # should match the same number of the records in the previous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- invoice_no: string (nullable = true)\n",
      " |-- invoice_date: date (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- stock_code: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      " |-- unit_price: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- is_missing_customer_id: boolean (nullable = false)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- day_of_month: integer (nullable = true)\n",
      " |-- day_of_year: integer (nullable = true)\n",
      " |-- week_of_year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- quarter: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- is_commercial_holiday: boolean (nullable = true)\n",
      " |-- is_commercial_holiday_week: boolean (nullable = true)\n",
      " |-- is_commercial_holiday_month: boolean (nullable = true)\n",
      " |-- is_bank_holiday: boolean (nullable = true)\n",
      " |-- is_bank_holiday_week: boolean (nullable = true)\n",
      " |-- is_bank_holiday_month: boolean (nullable = true)\n",
      " |-- is_cancelled: boolean (nullable = true)\n",
      " |-- is_return: boolean (nullable = true)\n",
      " |-- is_free_item: boolean (nullable = true)\n",
      " |-- total_item_price: double (nullable = true)\n",
      " |-- retail_price: string (nullable = true)\n",
      " |-- min_unit_price: double (nullable = true)\n",
      " |-- avg_unit_price: double (nullable = true)\n",
      " |-- median_unit_price: double (nullable = true)\n",
      " |-- max_unit_price: double (nullable = true)\n",
      " |-- is_discounted_item: boolean (nullable = true)\n",
      " |-- has_non_digit: boolean (nullable = true)\n",
      " |-- is_postage: boolean (nullable = true)\n",
      " |-- is_manual: boolean (nullable = true)\n",
      " |-- is_discount: boolean (nullable = true)\n",
      " |-- is_fee: boolean (nullable = true)\n",
      " |-- days_to_next_commercial_holiday: integer (nullable = true)\n",
      " |-- days_to_next_bank_holiday: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"# verifying schema:\\ndf_raw.printSchema()\";\n",
       "                var nbb_formatted_code = \"# verifying schema:\\ndf_raw.printSchema()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verifying schema:\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Addressing missing customers\n",
    "Previously, we observed that there are about 25% of records in the raw dataset that are associated with missing customer ids. I will now address these cases by trying to given unique identifiers to qualified records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"# visualizing some of the results with missing customers:\\ndf_missing_customer = df_raw.filter(df_raw.is_missing_customer_id == True)\";\n",
       "                var nbb_formatted_code = \"# visualizing some of the results with missing customers:\\ndf_missing_customer = df_raw.filter(df_raw.is_missing_customer_id == True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing some of the results with missing customers:\n",
    "df_missing_customer = df_raw.filter(df_raw.is_missing_customer_id == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>n_invoices_missing_customer</th></tr>\n",
       "<tr><td>3710</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------------------+\n",
       "|n_invoices_missing_customer|\n",
       "+---------------------------+\n",
       "|                       3710|\n",
       "+---------------------------+"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"# how many invoices with missing customer ids are there?\\ndf_missing_customer\\\\\\n    .select(F.countDistinct(F.col('invoice_no'))\\n             .alias('n_invoices_missing_customer'))\";\n",
       "                var nbb_formatted_code = \"# how many invoices with missing customer ids are there?\\ndf_missing_customer.select(\\n    F.countDistinct(F.col(\\\"invoice_no\\\")).alias(\\\"n_invoices_missing_customer\\\")\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how many invoices with missing customer ids are there?\n",
    "df_missing_customer.select(\n",
    "    F.countDistinct(F.col(\"invoice_no\")).alias(\"n_invoices_missing_customer\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are `3710` invoices missing customer ids, which represents about `14%` of the unique invoices. Let's first try to identify system-based invoices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_unformatted_code = \"# grouping on invoice level to get the invoices that are purely associated with returns and cancellations\\ndf_invoice_missing = (df_missing_customer\\n                         .groupby('invoice_no')\\n                         .agg(\\n                             F.first(F.col('customer_id')).alias('customer_id'),\\n                             F.min(F.abs(F.col('quantity'))).alias('min_quantity'),\\n                             F.max(F.abs(F.col('quantity'))).alias('max_quantity'),\\n                             F.avg(F.abs(F.col('quantity'))).alias('avg_quantity'),\\n                             F.min(F.abs(F.col('unit_price'))).alias('min_price'),\\n                             F.max(F.abs(F.col('unit_price'))).alias('max_price'),\\n                             F.avg(F.abs(F.col('unit_price'))).alias('avg_price'),\\n                             F.countDistinct(F.col('description')).alias('n_items'),\\n                             F.sum(F.when(F.col('is_return') == True, F.abs(F.col('quantity')))\\n                                    .otherwise(0)).alias('n_returned_items'),\\n                             F.sum(F.when(F.col('is_free_item') == True, F.abs(F.col('quantity')))\\n                                    .otherwise(0)).alias('n_free_items'),\\n                             F.sum(F.when(F.col('is_cancelled') == True, F.abs(F.col('quantity')))\\n                                    .otherwise(0)).alias('n_cancelled_items'),\\n                         ))\";\n",
       "                var nbb_formatted_code = \"# grouping on invoice level to get the invoices that are purely associated with returns and cancellations\\ndf_invoice_missing = df_missing_customer.groupby(\\\"invoice_no\\\").agg(\\n    F.first(F.col(\\\"customer_id\\\")).alias(\\\"customer_id\\\"),\\n    F.min(F.abs(F.col(\\\"quantity\\\"))).alias(\\\"min_quantity\\\"),\\n    F.max(F.abs(F.col(\\\"quantity\\\"))).alias(\\\"max_quantity\\\"),\\n    F.avg(F.abs(F.col(\\\"quantity\\\"))).alias(\\\"avg_quantity\\\"),\\n    F.min(F.abs(F.col(\\\"unit_price\\\"))).alias(\\\"min_price\\\"),\\n    F.max(F.abs(F.col(\\\"unit_price\\\"))).alias(\\\"max_price\\\"),\\n    F.avg(F.abs(F.col(\\\"unit_price\\\"))).alias(\\\"avg_price\\\"),\\n    F.countDistinct(F.col(\\\"description\\\")).alias(\\\"n_items\\\"),\\n    F.sum(\\n        F.when(F.col(\\\"is_return\\\") == True, F.abs(F.col(\\\"quantity\\\"))).otherwise(0)\\n    ).alias(\\\"n_returned_items\\\"),\\n    F.sum(\\n        F.when(F.col(\\\"is_free_item\\\") == True, F.abs(F.col(\\\"quantity\\\"))).otherwise(0)\\n    ).alias(\\\"n_free_items\\\"),\\n    F.sum(\\n        F.when(F.col(\\\"is_cancelled\\\") == True, F.abs(F.col(\\\"quantity\\\"))).otherwise(0)\\n    ).alias(\\\"n_cancelled_items\\\"),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grouping on invoice level to get the invoices that are purely associated with returns and cancellations\n",
    "df_invoice_missing = df_missing_customer.groupby(\"invoice_no\").agg(\n",
    "    F.first(F.col(\"customer_id\")).alias(\"customer_id\"),\n",
    "    F.min(F.abs(F.col(\"quantity\"))).alias(\"min_quantity\"),\n",
    "    F.max(F.abs(F.col(\"quantity\"))).alias(\"max_quantity\"),\n",
    "    F.avg(F.abs(F.col(\"quantity\"))).alias(\"avg_quantity\"),\n",
    "    F.min(F.abs(F.col(\"unit_price\"))).alias(\"min_price\"),\n",
    "    F.max(F.abs(F.col(\"unit_price\"))).alias(\"max_price\"),\n",
    "    F.avg(F.abs(F.col(\"unit_price\"))).alias(\"avg_price\"),\n",
    "    F.countDistinct(F.col(\"description\")).alias(\"n_items\"),\n",
    "    F.sum(\n",
    "        F.when(F.col(\"is_return\") == True, F.abs(F.col(\"quantity\"))).otherwise(0)\n",
    "    ).alias(\"n_returned_items\"),\n",
    "    F.sum(\n",
    "        F.when(F.col(\"is_free_item\") == True, F.abs(F.col(\"quantity\"))).otherwise(0)\n",
    "    ).alias(\"n_free_items\"),\n",
    "    F.sum(\n",
    "        F.when(F.col(\"is_cancelled\") == True, F.abs(F.col(\"quantity\"))).otherwise(0)\n",
    "    ).alias(\"n_cancelled_items\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3710"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 64;\n",
       "                var nbb_unformatted_code = \"# originally, we have the following number of records:\\ndf_invoice_missing.count()\";\n",
       "                var nbb_formatted_code = \"# originally, we have the following number of records:\\ndf_invoice_missing.count()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# originally, we have the following number of records:\n",
    "df_invoice_missing.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 65;\n",
       "                var nbb_unformatted_code = \"# removing the invoices that are related to one single item that is a return of free item \\ndf_invoice_missing_clean = (df_invoice_missing\\n                                .filter(~(F.col('min_quantity') == F.col('max_quantity'))\\n                                        & ~(F.col('min_quantity') == F.col('n_free_items'))\\n                                        & ~(F.col('n_items') == F.col('n_free_items'))\\n                                        & ~(F.col('n_items') == F.col('n_returned_items'))\\n                                        & ~(F.col('n_items') == F.col('n_cancelled_items'))))\";\n",
       "                var nbb_formatted_code = \"# removing the invoices that are related to one single item that is a return of free item\\ndf_invoice_missing_clean = df_invoice_missing.filter(\\n    ~(F.col(\\\"min_quantity\\\") == F.col(\\\"max_quantity\\\"))\\n    & ~(F.col(\\\"min_quantity\\\") == F.col(\\\"n_free_items\\\"))\\n    & ~(F.col(\\\"n_items\\\") == F.col(\\\"n_free_items\\\"))\\n    & ~(F.col(\\\"n_items\\\") == F.col(\\\"n_returned_items\\\"))\\n    & ~(F.col(\\\"n_items\\\") == F.col(\\\"n_cancelled_items\\\"))\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# removing the invoices that are related to one single item that is a return of free item\n",
    "df_invoice_missing_clean = df_invoice_missing.filter(\n",
    "    ~(F.col(\"min_quantity\") == F.col(\"max_quantity\"))\n",
    "    & ~(F.col(\"min_quantity\") == F.col(\"n_free_items\"))\n",
    "    & ~(F.col(\"n_items\") == F.col(\"n_free_items\"))\n",
    "    & ~(F.col(\"n_items\") == F.col(\"n_returned_items\"))\n",
    "    & ~(F.col(\"n_items\") == F.col(\"n_cancelled_items\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>invoice_no</th><th>customer_id</th><th>min_quantity</th><th>max_quantity</th><th>avg_quantity</th><th>min_price</th><th>max_price</th><th>avg_price</th><th>n_items</th><th>n_returned_items</th><th>n_free_items</th><th>n_cancelled_items</th></tr>\n",
       "<tr><td>570592</td><td>-1</td><td>1.0</td><td>75.0</td><td>7.438356164383562</td><td>1.63</td><td>24.96</td><td>5.493972602739724</td><td>72</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>580739</td><td>-1</td><td>2.0</td><td>3.0</td><td>2.5</td><td>2.08</td><td>2.1</td><td>2.09</td><td>2</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>538177</td><td>-1</td><td>1.0</td><td>29.0</td><td>2.445692883895131</td><td>0.42</td><td>847.42</td><td>6.64492509363296</td><td>530</td><td>0.0</td><td>143.0</td><td>0.0</td></tr>\n",
       "<tr><td>546892</td><td>-1</td><td>1.0</td><td>16.0</td><td>1.7908496732026145</td><td>0.42</td><td>192.44</td><td>5.022745098039215</td><td>153</td><td>0.0</td><td>32.0</td><td>0.0</td></tr>\n",
       "<tr><td>578539</td><td>-1</td><td>4.0</td><td>24.0</td><td>13.323529411764707</td><td>0.42</td><td>7.95</td><td>2.1073529411764707</td><td>34</td><td>0.0</td><td>200.0</td><td>0.0</td></tr>\n",
       "</table>\n",
       "only showing top 5 rows\n"
      ],
      "text/plain": [
       "+----------+-----------+------------+------------+------------------+---------+---------+------------------+-------+----------------+------------+-----------------+\n",
       "|invoice_no|customer_id|min_quantity|max_quantity|      avg_quantity|min_price|max_price|         avg_price|n_items|n_returned_items|n_free_items|n_cancelled_items|\n",
       "+----------+-----------+------------+------------+------------------+---------+---------+------------------+-------+----------------+------------+-----------------+\n",
       "|    570592|         -1|         1.0|        75.0| 7.438356164383562|     1.63|    24.96| 5.493972602739724|     72|             0.0|         0.0|              0.0|\n",
       "|    580739|         -1|         2.0|         3.0|               2.5|     2.08|      2.1|              2.09|      2|             0.0|         0.0|              0.0|\n",
       "|    538177|         -1|         1.0|        29.0| 2.445692883895131|     0.42|   847.42|  6.64492509363296|    530|             0.0|       143.0|              0.0|\n",
       "|    546892|         -1|         1.0|        16.0|1.7908496732026145|     0.42|   192.44| 5.022745098039215|    153|             0.0|        32.0|              0.0|\n",
       "|    578539|         -1|         4.0|        24.0|13.323529411764707|     0.42|     7.95|2.1073529411764707|     34|             0.0|       200.0|              0.0|\n",
       "+----------+-----------+------------+------------+------------------+---------+---------+------------------+-------+----------------+------------+-----------------+\n",
       "only showing top 5 rows"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 66;\n",
       "                var nbb_unformatted_code = \"# verifying the resulting dataframe:\\ndf_invoice_missing_clean\";\n",
       "                var nbb_formatted_code = \"# verifying the resulting dataframe:\\ndf_invoice_missing_clean\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verifying the resulting dataframe:\n",
    "df_invoice_missing_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 67;\n",
       "                var nbb_unformatted_code = \"# looking at the number of records in the cleaned data:\\ndf_invoice_missing_clean.count()\";\n",
       "                var nbb_formatted_code = \"# looking at the number of records in the cleaned data:\\ndf_invoice_missing_clean.count()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking at the number of records in the cleaned data:\n",
    "df_invoice_missing_clean.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These `1001` invoices can be treated as unique invoices with unique customers such that we can add artificial ids for such \"customers\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 68;\n",
       "                var nbb_unformatted_code = \"# adding an id column that starts from the max id in the dataset:\\nmax_id = (df_raw\\n             .filter(F.col('customer_id') != -1)\\n             .select(F.max(F.col('customer_id').cast('int'))\\n             .alias('customer_ids'))\\n             .collect()[0]['customer_ids']) \\n\\n# offsetting the max id by one to avoid duplicated ids\\nmax_id += 1\\n\\n\\n# defining a Window function to generate the uniquee index:\\nseq_id_window  = (Window\\n                      .partitionBy(\\\"customer_id\\\")\\n                      .orderBy(\\\"invoice_no\\\"))\\n\\ndf_invoice_missing_clean = (df_invoice_missing_clean\\n                                   .withColumn('temp_id',\\n                                               F.row_number().over(seq_id_window)\\n                                               + F.lit(max_id)))\";\n",
       "                var nbb_formatted_code = \"# adding an id column that starts from the max id in the dataset:\\nmax_id = (\\n    df_raw.filter(F.col(\\\"customer_id\\\") != -1)\\n    .select(F.max(F.col(\\\"customer_id\\\").cast(\\\"int\\\")).alias(\\\"customer_ids\\\"))\\n    .collect()[0][\\\"customer_ids\\\"]\\n)\\n\\n# offsetting the max id by one to avoid duplicated ids\\nmax_id += 1\\n\\n\\n# defining a Window function to generate the uniquee index:\\nseq_id_window = Window.partitionBy(\\\"customer_id\\\").orderBy(\\\"invoice_no\\\")\\n\\ndf_invoice_missing_clean = df_invoice_missing_clean.withColumn(\\n    \\\"temp_id\\\", F.row_number().over(seq_id_window) + F.lit(max_id)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding an id column that starts from the max id in the dataset:\n",
    "max_id = (\n",
    "    df_raw.filter(F.col(\"customer_id\") != -1)\n",
    "    .select(F.max(F.col(\"customer_id\").cast(\"int\")).alias(\"customer_ids\"))\n",
    "    .collect()[0][\"customer_ids\"]\n",
    ")\n",
    "\n",
    "# offsetting the max id by one to avoid duplicated ids\n",
    "max_id += 1\n",
    "\n",
    "\n",
    "# defining a Window function to generate the uniquee index:\n",
    "seq_id_window = Window.partitionBy(\"customer_id\").orderBy(\"invoice_no\")\n",
    "\n",
    "df_invoice_missing_clean = df_invoice_missing_clean.withColumn(\n",
    "    \"temp_id\", F.row_number().over(seq_id_window) + F.lit(max_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 69;\n",
       "                var nbb_unformatted_code = \"# selecting the relevant columnss:\\ndf_invoice_missing = (df_invoice_missing_clean\\n                           .select('invoice_no', \\n                                   'temp_id'))\";\n",
       "                var nbb_formatted_code = \"# selecting the relevant columnss:\\ndf_invoice_missing = df_invoice_missing_clean.select(\\\"invoice_no\\\", \\\"temp_id\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# selecting the relevant columnss:\n",
    "df_invoice_missing = df_invoice_missing_clean.select(\"invoice_no\", \"temp_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 70;\n",
       "                var nbb_unformatted_code = \"# joining back the identified ids to the original dataset:\\ndf_raw = (df_raw\\n             .join(\\n                 df_invoice_missing,\\n                 how = 'left',\\n                 on = ['invoice_no']\\n             ))\";\n",
       "                var nbb_formatted_code = \"# joining back the identified ids to the original dataset:\\ndf_raw = df_raw.join(df_invoice_missing, how=\\\"left\\\", on=[\\\"invoice_no\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# joining back the identified ids to the original dataset:\n",
    "df_raw = df_raw.join(df_invoice_missing, how=\"left\", on=[\"invoice_no\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 71;\n",
       "                var nbb_unformatted_code = \"# performing the substitution:\\ndf_raw = (df_raw\\n             .withColumn(\\n                 'customer_id',\\n                 F.when((F.col('customer_id') == -1)\\n                        & (F.col('temp_id').isNotNull()),\\n                        F.col('temp_id'))\\n                  .otherwise(F.col('customer_id'))\\n             ))\";\n",
       "                var nbb_formatted_code = \"# performing the substitution:\\ndf_raw = df_raw.withColumn(\\n    \\\"customer_id\\\",\\n    F.when(\\n        (F.col(\\\"customer_id\\\") == -1) & (F.col(\\\"temp_id\\\").isNotNull()), F.col(\\\"temp_id\\\")\\n    ).otherwise(F.col(\\\"customer_id\\\")),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# performing the substitution:\n",
    "df_raw = df_raw.withColumn(\n",
    "    \"customer_id\",\n",
    "    F.when(\n",
    "        (F.col(\"customer_id\") == -1) & (F.col(\"temp_id\").isNotNull()), F.col(\"temp_id\")\n",
    "    ).otherwise(F.col(\"customer_id\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 72;\n",
       "                var nbb_unformatted_code = \"# filtering out the data related to customers that are still missing:\\ndf_clean = (df_raw\\n               .filter(F.col('customer_id') != -1))\";\n",
       "                var nbb_formatted_code = \"# filtering out the data related to customers that are still missing:\\ndf_clean = df_raw.filter(F.col(\\\"customer_id\\\") != -1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filtering out the data related to customers that are still missing:\n",
    "df_clean = df_raw.filter(F.col(\"customer_id\") != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>n_invoices_remaining</th></tr>\n",
       "<tr><td>23191</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+\n",
       "|n_invoices_remaining|\n",
       "+--------------------+\n",
       "|               23191|\n",
       "+--------------------+"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 73;\n",
       "                var nbb_unformatted_code = \"df_clean\\\\\\n    .select(F.countDistinct(F.col('invoice_no'))\\n    .alias('n_invoices_remaining')) # should return the expected amount of ids\";\n",
       "                var nbb_formatted_code = \"df_clean.select(\\n    F.countDistinct(F.col(\\\"invoice_no\\\")).alias(\\\"n_invoices_remaining\\\")\\n)  # should return the expected amount of ids\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_clean.select(\n",
    "    F.countDistinct(F.col(\"invoice_no\")).alias(\"n_invoices_remaining\")\n",
    ")  # should return the expected amount of ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 74;\n",
       "                var nbb_unformatted_code = \"# dropping the unnecessary column:\\ndf_clean = (df_clean\\n               .drop('temp_id'))\";\n",
       "                var nbb_formatted_code = \"# dropping the unnecessary column:\\ndf_clean = df_clean.drop(\\\"temp_id\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dropping the unnecessary column:\n",
    "df_clean = df_clean.drop(\"temp_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Saving the Dataset\n",
    "In the real world, I would often approach saving a dataset in a few different ways, such as:\n",
    "\n",
    "1. Writing the dataset to an object store for use in further steps of the data pipeline (Amazon's `s3`, for example);\n",
    "2. Writing the dataset as a table in some distributed file system (`hdfs` or even `s3`) with relevant metadata associated (such that it can be queried through `Hive` or Amazon's `Athena`);\n",
    "3. Writing the results of the dataset directly to a database for use in different applications (`Postgresql`, `Redshift`, et cetera);\n",
    "\n",
    "For this project, I won't be using such infra-structure, but I will simulate it by writing to a \"object store\", which, in this case, is the file system of my computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 75;\n",
       "                var nbb_unformatted_code = \"# saving the enhanced raw data as parquet in the processed step of the pipeline\\nPROCESSED_DATA_DIR = '../data/processed'\\n\\n# using the helper function to save the file:\\nsave_to_filesystem(df_clean, \\n                   PROCESSED_DATA_DIR,\\n                  'tb_ecommerce',\\n                  'tb_ecommerce.parquet')\";\n",
       "                var nbb_formatted_code = \"# saving the enhanced raw data as parquet in the processed step of the pipeline\\nPROCESSED_DATA_DIR = \\\"../data/processed\\\"\\n\\n# using the helper function to save the file:\\nsave_to_filesystem(df_clean, PROCESSED_DATA_DIR, \\\"tb_ecommerce\\\", \\\"tb_ecommerce.parquet\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# saving the enhanced raw data as parquet in the processed step of the pipeline\n",
    "PROCESSED_DATA_DIR = \"../data/processed\"\n",
    "\n",
    "# using the helper function to save the file:\n",
    "save_to_filesystem(df_clean, PROCESSED_DATA_DIR, \"tb_ecommerce\", \"tb_ecommerce.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
